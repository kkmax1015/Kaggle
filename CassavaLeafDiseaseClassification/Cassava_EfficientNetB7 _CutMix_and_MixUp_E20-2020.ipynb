{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"papermill":{"duration":2705.650201,"end_time":"2021-01-20T23:42:08.938285","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-01-20T22:57:03.288084","version":"2.1.0"},"colab":{"name":"Cassava - EfficientNetB7 -CutMix and MixUp-E20-No2019.ipynb","provenance":[{"file_id":"1ZgPO3NjZoFnZRA9GQ03bBGBmT3B1kHVw","timestamp":1613061387022},{"file_id":"1-ZoJbdw3oWULsug_imAutWQbucAV1_f-","timestamp":1612628699360},{"file_id":"1k3GJEDIw5B9smNhmCO9z5wJn0_fz7V6e","timestamp":1612360146025},{"file_id":"1luIn2wZfy_fopw5CZhO7tSwz3QfPBeu0","timestamp":1611649047226},{"file_id":"14lxnkhkxhL-leLaM7_ewQrCSbDr617ZZ","timestamp":1611576808109}],"collapsed_sections":[]},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:08.648534Z","iopub.status.busy":"2021-01-20T22:57:08.647654Z","iopub.status.idle":"2021-01-20T22:57:08.650554Z","shell.execute_reply":"2021-01-20T22:57:08.651069Z"},"papermill":{"duration":0.038327,"end_time":"2021-01-20T22:57:08.651252","exception":false,"start_time":"2021-01-20T22:57:08.612925","status":"completed"},"tags":[],"id":"BkVGwREBxGQy","executionInfo":{"status":"ok","timestamp":1613126348601,"user_tz":-540,"elapsed":570,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["EPOCHS = 20 \n","HEIGHT = 512\n","WIDTH = 512\n","HEIGHT_RS = 512\n","WIDTH_RS = 512\n","CHANNELS = 3\n","N_CLASSES = 5\n","N_FOLDS = 5\n","FOLDS_USED = 5\n","ES_PATIENCE = 5\n","IMAGE_SIZE = [512, 512]"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:08.738880Z","iopub.status.busy":"2021-01-20T22:57:08.723182Z","iopub.status.idle":"2021-01-20T22:57:11.217685Z","shell.execute_reply":"2021-01-20T22:57:11.216355Z"},"id":"YZBauHrJCkn7","papermill":{"duration":2.537229,"end_time":"2021-01-20T22:57:11.217823","exception":false,"start_time":"2021-01-20T22:57:08.680594","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613126395060,"user_tz":-540,"elapsed":47017,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"f3cf1165-ba45-464e-bf5e-257a005f8670"},"source":["\n","import os\n","\n","models_path=''\n","\n","\n","\n","\n","\n","COLAB=True\n","import gc\n","!pip install fsspec\n","!pip install gcsfs \n","!pip install --upgrade --force-reinstall --no-deps kaggle\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/MyDrive/Colab Notebooks/Cassava/'\n","\n","#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","\n","database_base_path = 'gs://kds-e118bcdb309cf88b7f9e4a96ee84997123a5781b886180ffc13d3fc9'\n","GCS_PATH = 'gs://kds-73ad24bb2e88a88d616d183727bf88d16deab7892840afc75a21cc90'\n","GCS_PATH_EXT = 'gs://kds-45c6060e9b2c39c0152e5fb66610110218c984e18c09a40d3f7b23d0'\n","GCS_PATH_CLASSES = 'gs://kds-214b31c2a1f93777a325b30beb67b72cda39e60b413aeaa16bff7396'\n","GCS_PATH_EXT_CLASSES = 'gs://kds-46c36b9b602c0da9228d8da71233604d6a4d98c9b36e7e9598d3dceb'\n","\n","\n","# \n","#This is a path to a dataset that changes over time, so you need to constantly update it. To update the path just run the code: \n","#GCS_DS_PATH = KaggleDatasets (). Get_gcs_path ()\n","#print (GCS_PATH)......\n","models_path='/content/drive/MyDrive/Colab Notebooks/Cassava/model/'# I created a folder called Models/Cassava on my Google Drive"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: fsspec in /usr/local/lib/python3.6/dist-packages (0.8.5)\n","Requirement already satisfied: gcsfs in /usr/local/lib/python3.6/dist-packages (0.7.2)\n","Requirement already satisfied: fsspec>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.8.5)\n","Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.25.0)\n","Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.23.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.6/dist-packages (from gcsfs) (3.7.3)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.2.1)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (53.0.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.7)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.10)\n","Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (1.1.0)\n","Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (3.0.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (5.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (3.7.4.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (20.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (1.6.3)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n","Processing /root/.cache/pip/wheels/3a/d1/7e/6ce09b72b770149802c653a02783821629146983ee5a360f10/kaggle-1.5.10-cp36-none-any.whl\n","Installing collected packages: kaggle\n","  Found existing installation: kaggle 1.5.10\n","    Uninstalling kaggle-1.5.10:\n","      Successfully uninstalled kaggle-1.5.10\n","Successfully installed kaggle-1.5.10\n","Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/Cassava\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:11.294556Z","iopub.status.busy":"2021-01-20T22:57:11.290187Z","iopub.status.idle":"2021-01-20T22:57:11.298693Z","shell.execute_reply":"2021-01-20T22:57:11.298011Z"},"id":"5V15UaoACh-M","papermill":{"duration":0.051661,"end_time":"2021-01-20T22:57:11.298873","exception":false,"start_time":"2021-01-20T22:57:11.247212","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613126395417,"user_tz":-540,"elapsed":47368,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["if COLAB:# Prepare the kaggle.json file for use \n","    from google.colab import files\n","    if not os.path.exists('/content/drive/MyDrive/Colab Notebooks/.kaggle/kaggle.json'):\n","        !mkdir ~/content/drive/MyDrive/Colab Notebooks/.kaggle/\n","        if not os.path.exists('/content/drive/MyDrive/Colab Notebooks/.kaggle/kaggle.json'):\n","            files.upload()\n","            !cp kaggle.json ~/content/drive/MyDrive/Colab Notebooks/.kaggle/\n","        else:\n","            !cp '/content/drive/MyDrive/Colab Notebooks/' ~/.kaggle/  \n","        !chmod 600 ~/content/drive/MyDrive/Colab Notebooks/.kaggle/kaggle.json\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:11.368941Z","iopub.status.busy":"2021-01-20T22:57:11.367797Z","iopub.status.idle":"2021-01-20T22:57:11.371432Z","shell.execute_reply":"2021-01-20T22:57:11.370752Z"},"id":"urYjsB4IV-t5","papermill":{"duration":0.04238,"end_time":"2021-01-20T22:57:11.371550","exception":false,"start_time":"2021-01-20T22:57:11.329170","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613126519202,"user_tz":-540,"elapsed":171149,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"c3d2c7f3-da01-44f7-f4f2-a82a197f29ea"},"source":["if COLAB:# force TF to 2.2\n","    !pip install -q tensorflow~=2.2.0 tensorflow_gcs_config~=2.2.0\n","    \n","    import requests\n","    import os\n","    import tensorflow as tf\n","    resp = requests.post(\"http://{}:8475/requestversion/{}\".format(os.environ[\"COLAB_TPU_ADDR\"].split(\":\")[0], tf.__version__))\n","    if resp.status_code != 200:\n","      print(\"Failed to switch the TPU to TF {}\".format(version))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 516.2MB 32kB/s \n","\u001b[K     |████████████████████████████████| 399kB 26.2MB/s \n","\u001b[K     |████████████████████████████████| 460kB 39.5MB/s \n","\u001b[K     |████████████████████████████████| 20.1MB 168kB/s \n","\u001b[K     |████████████████████████████████| 3.0MB 35.2MB/s \n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DJLH967uCaOv","papermill":{"duration":0.029839,"end_time":"2021-01-20T22:57:11.431128","exception":false,"start_time":"2021-01-20T22:57:11.401289","status":"completed"},"tags":[]},"source":["## Dependencies"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:11.498391Z","iopub.status.busy":"2021-01-20T22:57:11.497630Z","iopub.status.idle":"2021-01-20T22:57:21.909368Z","shell.execute_reply":"2021-01-20T22:57:21.908714Z"},"id":"u8lneueOCaOv","papermill":{"duration":10.446497,"end_time":"2021-01-20T22:57:21.909508","exception":false,"start_time":"2021-01-20T22:57:11.463011","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613126522339,"user_tz":-540,"elapsed":174282,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"73b112a9-6ce7-404f-93ff-6fddb72e8b6d"},"source":["!pip install --quiet efficientnet"],"execution_count":7,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |██████▌                         | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.8MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:21.982695Z","iopub.status.busy":"2021-01-20T22:57:21.981961Z","iopub.status.idle":"2021-01-20T22:57:29.891530Z","shell.execute_reply":"2021-01-20T22:57:29.890624Z"},"id":"-iMoIRz7CaOw","papermill":{"duration":7.952124,"end_time":"2021-01-20T22:57:29.891659","exception":false,"start_time":"2021-01-20T22:57:21.939535","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613126523727,"user_tz":-540,"elapsed":175666,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["import math, os, re, warnings, random, time\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import classification_report, confusion_matrix\n","import tensorflow as tf\n","import tensorflow.keras.layers as L\n","import tensorflow.keras.backend as K\n","from tensorflow.keras import optimizers, Sequential, losses, metrics, Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","import efficientnet.tfkeras as efn\n","\n","def seed_everything(seed=0):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","seed = 0\n","seed_everything(seed)\n","warnings.filterwarnings('ignore')"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z-146lSGCaOx","papermill":{"duration":0.030316,"end_time":"2021-01-20T22:57:29.954488","exception":false,"start_time":"2021-01-20T22:57:29.924172","status":"completed"},"tags":[]},"source":["### Hardware configuration\n","\n","Note that we have `32` cores, this is because the `TPU v2 Pod` have more cores than a single `TPU v3` which has `8` cores."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:30.071569Z","iopub.status.busy":"2021-01-20T22:57:30.035804Z","iopub.status.idle":"2021-01-20T22:57:34.008561Z","shell.execute_reply":"2021-01-20T22:57:34.010162Z"},"id":"cCFwEwkVCaOy","papermill":{"duration":4.024986,"end_time":"2021-01-20T22:57:34.010410","exception":false,"start_time":"2021-01-20T22:57:29.985424","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613126554694,"user_tz":-540,"elapsed":206630,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"4bbf719a-ade8-4e04-eafb-597edf394b1f"},"source":["# TPU or GPU detection\n","# Detect hardware, return appropriate distribution strategy\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print(f'Running on TPU {tpu.master()}')\n","except ValueError:\n","    tpu = None\n","    print ('tpu',tpu)\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","else:\n","    strategy = tf.distribute.get_strategy()\n","\n","AUTO = tf.data.experimental.AUTOTUNE\n","REPLICAS = strategy.num_replicas_in_sync\n","print(f'REPLICAS: {REPLICAS}')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Running on TPU grpc://10.84.237.202:8470\n","INFO:tensorflow:Initializing the TPU system: grpc://10.84.237.202:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.84.237.202:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["REPLICAS: 8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NK8TAx9JCaOz","papermill":{"duration":0.035404,"end_time":"2021-01-20T22:57:34.088585","exception":false,"start_time":"2021-01-20T22:57:34.053181","status":"completed"},"tags":[]},"source":["# Model parameters"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:34.155750Z","iopub.status.busy":"2021-01-20T22:57:34.154661Z","iopub.status.idle":"2021-01-20T22:57:34.160980Z","shell.execute_reply":"2021-01-20T22:57:34.160280Z"},"papermill":{"duration":0.040682,"end_time":"2021-01-20T22:57:34.161109","exception":false,"start_time":"2021-01-20T22:57:34.120427","status":"completed"},"tags":[],"id":"hyxJUKF-xGQ2","executionInfo":{"status":"ok","timestamp":1613126554850,"user_tz":-540,"elapsed":206782,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["BATCH_SIZE = 8 * REPLICAS\n","AUG_BATCH = BATCH_SIZE\n","LEARNING_RATE = 1e-5 * REPLICAS"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UmwrOwlYCaOz","papermill":{"duration":0.031304,"end_time":"2021-01-20T22:57:34.223728","exception":false,"start_time":"2021-01-20T22:57:34.192424","status":"completed"},"tags":[]},"source":["# Load data"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:34.290296Z","iopub.status.busy":"2021-01-20T22:57:34.289242Z","iopub.status.idle":"2021-01-20T22:57:35.971447Z","shell.execute_reply":"2021-01-20T22:57:35.971977Z"},"id":"UxM4MGNGCaO0","papermill":{"duration":1.717316,"end_time":"2021-01-20T22:57:35.972129","exception":false,"start_time":"2021-01-20T22:57:34.254813","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1613126556474,"user_tz":-540,"elapsed":208403,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"492a5365-ec7c-4acc-ee99-99fb9de4a91e"},"source":["def count_data_items(filenames):\n","    n = [int(re.compile(r'-([0-9]*)\\.').search(filename).group(1)) for filename in filenames]\n","    return np.sum(n)\n","\n","\n","train = pd.read_csv(f'{database_base_path}/train.csv')\n","print(f'Train samples: {len(train)}')\n","\n","FILENAMES_COMP = tf.io.gfile.glob(GCS_PATH + '/*.tfrec')\n","#FILENAMES_2019 = tf.io.gfile.glob(GCS_PATH_EXT + '/*.tfrec')\n","\n","FILENAMES_COMP_CBB = tf.io.gfile.glob(GCS_PATH_CLASSES + '/CBB*.tfrec')\n","FILENAMES_COMP_CBSD = tf.io.gfile.glob(GCS_PATH_CLASSES + '/CBSD*.tfrec')\n","FILENAMES_COMP_CGM = tf.io.gfile.glob(GCS_PATH_CLASSES + '/CGM*.tfrec')\n","FILENAMES_COMP_CMD = tf.io.gfile.glob(GCS_PATH_CLASSES + '/CMD*.tfrec')\n","FILENAMES_COMP_Healthy = tf.io.gfile.glob(GCS_PATH_CLASSES + '/Healthy*.tfrec')\n","\n","# FILENAMES_2019_CBB = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/CBB*.tfrec')\n","# FILENAMES_2019_CBSD = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/CBSD*.tfrec')\n","# FILENAMES_2019_CGM = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/CGM*.tfrec')\n","# FILENAMES_2019_CMD = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/CMD*.tfrec')\n","# FILENAMES_2019_Healthy = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/Healthy*.tfrec')\n","\n","\n","TRAINING_FILENAMES = (FILENAMES_COMP + \n","                      # FILENAMES_2019 + \n","                      (2 * FILENAMES_COMP_CBB) + \n","                      # (2 * FILENAMES_2019_CBB) + \n","                      (2 * FILENAMES_COMP_CBSD) + \n","                      # (2 * FILENAMES_2019_CBSD) + \n","                      (2 * FILENAMES_COMP_CGM) + \n","                      # (2 * FILENAMES_2019_CGM) + \n","                      (2 * FILENAMES_COMP_Healthy))\n","                      # (2 * FILENAMES_2019_Healthy))\n","\n","NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n","\n","print(f'GCS: train images: {NUM_TRAINING_IMAGES}')\n","display(train.head())\n","\n","CLASSES = ['Cassava Bacterial Blight', \n","           'Cassava Brown Streak Disease', \n","           'Cassava Green Mottle', \n","           'Cassava Mosaic Disease', \n","           'Healthy']"],"execution_count":11,"outputs":[{"output_type":"stream","text":["WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable onattempt 1 of 3. Reason: [Errno 115] Operation now in progress\n","WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable onattempt 2 of 3. Reason: [Errno 115] Operation now in progress\n","WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable onattempt 3 of 3. Reason: [Errno 115] Operation now in progress\n","WARNING:google.auth._default:Authentication failed using Compute Engine authentication due to unavailable metadata server.\n"],"name":"stderr"},{"output_type":"stream","text":["Train samples: 21397\n","GCS: train images: 37869\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_id</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000015157.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000201771.jpg</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>100042118.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000723321.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000812911.jpg</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         image_id  label\n","0  1000015157.jpg      0\n","1  1000201771.jpg      3\n","2   100042118.jpg      1\n","3  1000723321.jpg      1\n","4  1000812911.jpg      3"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"BZIhYsg_CaO1","papermill":{"duration":0.032803,"end_time":"2021-01-20T22:57:36.037731","exception":false,"start_time":"2021-01-20T22:57:36.004928","status":"completed"},"tags":[]},"source":["# Augmentation"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:36.106682Z","iopub.status.busy":"2021-01-20T22:57:36.105973Z","iopub.status.idle":"2021-01-20T22:57:36.133193Z","shell.execute_reply":"2021-01-20T22:57:36.133788Z"},"id":"Wwh329L6CaO1","papermill":{"duration":0.063522,"end_time":"2021-01-20T22:57:36.133965","exception":false,"start_time":"2021-01-20T22:57:36.070443","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613126556635,"user_tz":-540,"elapsed":208559,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["def data_augment(image, label):\n","    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    \n","    # Shear\n","    if p_shear > .2:\n","        if p_shear > .6:\n","            image = transform_shear(image, HEIGHT, shear=20.)\n","        else:\n","            image = transform_shear(image, HEIGHT, shear=-20.)\n","            \n","    # Rotation\n","    if p_rotation > .2:\n","        if p_rotation > .6:\n","            image = transform_rotation(image, HEIGHT, rotation=45.)\n","        else:\n","            image = transform_rotation(image, HEIGHT, rotation=-45.)\n","            \n","    # Flips\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_flip_up_down(image)\n","    if p_spatial > .75:\n","        image = tf.image.transpose(image)\n","        \n","    # Rotates\n","    if p_rotate > .75:\n","        image = tf.image.rot90(image, k=3) # rotate 270º\n","    elif p_rotate > .5:\n","        image = tf.image.rot90(image, k=2) # rotate 180º\n","    elif p_rotate > .25:\n","        image = tf.image.rot90(image, k=1) # rotate 90º\n","        \n","    # Pixel-level transforms\n","    if p_pixel_1 >= .4:\n","        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n","    if p_pixel_2 >= .4:\n","        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n","    if p_pixel_3 >= .4:\n","        image = tf.image.random_brightness(image, max_delta=.1)\n","        \n","    # Crops\n","    if p_crop > .6:\n","        if p_crop > .9:\n","            image = tf.image.central_crop(image, central_fraction=.5)\n","        elif p_crop > .8:\n","            image = tf.image.central_crop(image, central_fraction=.6)\n","        elif p_crop > .7:\n","            image = tf.image.central_crop(image, central_fraction=.7)\n","        else:\n","            image = tf.image.central_crop(image, central_fraction=.8)\n","    elif p_crop > .3:\n","        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n","        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n","            \n","    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n","\n","    # if p_cutout > .5:\n","    #     image = data_augment_cutout(image)\n","        \n","    return image, label"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r4Hg1nKgCaO1","papermill":{"duration":0.033215,"end_time":"2021-01-20T22:57:36.199741","exception":false,"start_time":"2021-01-20T22:57:36.166526","status":"completed"},"tags":[]},"source":["## Auxiliary functions"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:36.295009Z","iopub.status.busy":"2021-01-20T22:57:36.289488Z","iopub.status.idle":"2021-01-20T22:57:36.318353Z","shell.execute_reply":"2021-01-20T22:57:36.317633Z"},"id":"-DueNRgfCaO1","papermill":{"duration":0.08607,"end_time":"2021-01-20T22:57:36.318490","exception":false,"start_time":"2021-01-20T22:57:36.232420","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613126556814,"user_tz":-540,"elapsed":208734,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n","def transform_rotation(image, height, rotation):\n","    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n","    # output - image randomly rotated\n","    DIM = height\n","    XDIM = DIM%2 #fix for size 331\n","    \n","    rotation = rotation * tf.random.uniform([1],dtype='float32')\n","    # CONVERT DEGREES TO RADIANS\n","    rotation = math.pi * rotation / 180.\n","    \n","    # ROTATION MATRIX\n","    c1 = tf.math.cos(rotation)\n","    s1 = tf.math.sin(rotation)\n","    one = tf.constant([1],dtype='float32')\n","    zero = tf.constant([0],dtype='float32')\n","    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n","\n","    # LIST DESTINATION PIXEL INDICES\n","    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n","    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n","    z = tf.ones([DIM*DIM],dtype='int32')\n","    idx = tf.stack( [x,y,z] )\n","    \n","    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n","    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n","    idx2 = K.cast(idx2,dtype='int32')\n","    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n","    \n","    # FIND ORIGIN PIXEL VALUES \n","    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n","    d = tf.gather_nd(image, tf.transpose(idx3))\n","        \n","    return tf.reshape(d,[DIM,DIM,3])\n","\n","def transform_shear(image, height, shear):\n","    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n","    # output - image randomly sheared\n","    DIM = height\n","    XDIM = DIM%2 #fix for size 331\n","    \n","    shear = shear * tf.random.uniform([1],dtype='float32')\n","    shear = math.pi * shear / 180.\n","        \n","    # SHEAR MATRIX\n","    one = tf.constant([1],dtype='float32')\n","    zero = tf.constant([0],dtype='float32')\n","    c2 = tf.math.cos(shear)\n","    s2 = tf.math.sin(shear)\n","    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n","\n","    # LIST DESTINATION PIXEL INDICES\n","    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n","    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n","    z = tf.ones([DIM*DIM],dtype='int32')\n","    idx = tf.stack( [x,y,z] )\n","    \n","    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n","    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n","    idx2 = K.cast(idx2,dtype='int32')\n","    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n","    \n","    # FIND ORIGIN PIXEL VALUES \n","    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n","    d = tf.gather_nd(image, tf.transpose(idx3))\n","        \n","    return tf.reshape(d,[DIM,DIM,3])\n","\n","# CutOut\n","def data_augment_cutout(image, min_mask_size=(int(HEIGHT * .1), int(HEIGHT * .1)), \n","                        max_mask_size=(int(HEIGHT * .125), int(HEIGHT * .125))):\n","    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    \n","    if p_cutout > .85: # 10~15 cut outs\n","        n_cutout = tf.random.uniform([], 10, 15, dtype=tf.int32)\n","        image = random_cutout(image, HEIGHT, WIDTH, \n","                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n","    elif p_cutout > .6: # 5~10 cut outs\n","        n_cutout = tf.random.uniform([], 5, 10, dtype=tf.int32)\n","        image = random_cutout(image, HEIGHT, WIDTH, \n","                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n","    elif p_cutout > .25: # 2~5 cut outs\n","        n_cutout = tf.random.uniform([], 2, 5, dtype=tf.int32)\n","        image = random_cutout(image, HEIGHT, WIDTH, \n","                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n","    else: # 1 cut out\n","        image = random_cutout(image, HEIGHT, WIDTH, \n","                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=1)\n","\n","    return image\n","\n","def random_cutout(image, height, width, channels=3, min_mask_size=(10, 10), max_mask_size=(80, 80), k=1):\n","    assert height > min_mask_size[0]\n","    assert width > min_mask_size[1]\n","    assert height > max_mask_size[0]\n","    assert width > max_mask_size[1]\n","\n","    for i in range(k):\n","      mask_height = tf.random.uniform(shape=[], minval=min_mask_size[0], maxval=max_mask_size[0], dtype=tf.int32)\n","      mask_width = tf.random.uniform(shape=[], minval=min_mask_size[1], maxval=max_mask_size[1], dtype=tf.int32)\n","\n","      pad_h = height - mask_height\n","      pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n","      pad_bottom = pad_h - pad_top\n","\n","      pad_w = width - mask_width\n","      pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n","      pad_right = pad_w - pad_left\n","\n","      cutout_area = tf.zeros(shape=[mask_height, mask_width, channels], dtype=tf.uint8)\n","\n","      cutout_mask = tf.pad([cutout_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n","      cutout_mask = tf.squeeze(cutout_mask, axis=0)\n","      image = tf.multiply(tf.cast(image, tf.float32), tf.cast(cutout_mask, tf.float32))\n","\n","    return image"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hyi3J0MXvJBz","executionInfo":{"status":"ok","timestamp":1613126556815,"user_tz":-540,"elapsed":208732,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["def cutmix(image, label, PROBABILITY = 1.0):\r\n","    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\r\n","    # output - a batch of images with cutmix applied\r\n","    DIM = IMAGE_SIZE[0]\r\n","    CLASSES = N_CLASSES\r\n","    \r\n","    imgs = []; labs = []\r\n","    for j in range(AUG_BATCH):\r\n","        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\r\n","        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\r\n","        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\r\n","        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\r\n","        # CHOOSE RANDOM LOCATION\r\n","        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\r\n","        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\r\n","        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\r\n","        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\r\n","        ya = tf.math.maximum(0,y-WIDTH//2)\r\n","        yb = tf.math.minimum(DIM,y+WIDTH//2)\r\n","        xa = tf.math.maximum(0,x-WIDTH//2)\r\n","        xb = tf.math.minimum(DIM,x+WIDTH//2)\r\n","        # MAKE CUTMIX IMAGE\r\n","        one = image[j,ya:yb,0:xa,:]\r\n","        two = image[k,ya:yb,xa:xb,:]\r\n","        three = image[j,ya:yb,xb:DIM,:]\r\n","        middle = tf.concat([one,two,three],axis=1)\r\n","        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\r\n","        imgs.append(img)\r\n","        # MAKE CUTMIX LABEL\r\n","        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\r\n","        if len(label.shape)==1:\r\n","            lab1 = tf.one_hot(label[j],CLASSES)\r\n","            lab2 = tf.one_hot(label[k],CLASSES)\r\n","        else:\r\n","            lab1 = label[j,]\r\n","            lab2 = label[k,]\r\n","        labs.append((1-a)*lab1 + a*lab2)\r\n","            \r\n","    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\r\n","    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\r\n","    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\r\n","    return image2,label2"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"VD277mUEvLBE","executionInfo":{"status":"ok","timestamp":1613126556815,"user_tz":-540,"elapsed":208728,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["def mixup(image, label, PROBABILITY = 1.0):\r\n","    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\r\n","    # output - a batch of images with mixup applied\r\n","    DIM = IMAGE_SIZE[0]\r\n","    CLASSES = N_CLASSES\r\n","    \r\n","    imgs = []; labs = []\r\n","    for j in range(AUG_BATCH):\r\n","        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\r\n","        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\r\n","        # CHOOSE RANDOM\r\n","        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\r\n","        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\r\n","        # MAKE MIXUP IMAGE\r\n","        img1 = image[j,]\r\n","        img2 = image[k,]\r\n","        imgs.append((1-a)*img1 + a*img2)\r\n","        # MAKE CUTMIX LABEL\r\n","        if len(label.shape)==1:\r\n","            lab1 = tf.one_hot(label[j],CLASSES)\r\n","            lab2 = tf.one_hot(label[k],CLASSES)\r\n","        else:\r\n","            lab1 = label[j,]\r\n","            lab2 = label[k,]\r\n","        labs.append((1-a)*lab1 + a*lab2)\r\n","            \r\n","    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\r\n","    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\r\n","    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\r\n","    return image2,label2"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"AdQEC_iKvR3z","executionInfo":{"status":"ok","timestamp":1613126556816,"user_tz":-540,"elapsed":208726,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["def transform(image,label):\r\n","    # THIS FUNCTION APPLIES BOTH CUTMIX AND MIXUP\r\n","    DIM = IMAGE_SIZE[0]\r\n","    CLASSES = N_CLASSES\r\n","    SWITCH = 0.5\r\n","    CUTMIX_PROB = 0.666\r\n","    MIXUP_PROB = 0.666\r\n","    # FOR SWITCH PERCENT OF TIME WE DO CUTMIX AND (1-SWITCH) WE DO MIXUP\r\n","    image2, label2 = cutmix(image, label, CUTMIX_PROB)\r\n","    image3, label3 = mixup(image, label, MIXUP_PROB)\r\n","    imgs = []; labs = []\r\n","    for j in range(AUG_BATCH):\r\n","        P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\r\n","        imgs.append(P*image2[j,]+(1-P)*image3[j,])\r\n","        labs.append(P*label2[j,]+(1-P)*label3[j,])\r\n","    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\r\n","    image4 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\r\n","    label4 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\r\n","    return image4,label4"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:36.388974Z","iopub.status.busy":"2021-01-20T22:57:36.388107Z","iopub.status.idle":"2021-01-20T22:57:36.415254Z","shell.execute_reply":"2021-01-20T22:57:36.415771Z"},"id":"CPcg0bWECaO1","papermill":{"duration":0.064439,"end_time":"2021-01-20T22:57:36.415960","exception":false,"start_time":"2021-01-20T22:57:36.351521","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613126557070,"user_tz":-540,"elapsed":208977,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["# Datasets utility functions\n","def decode_image(image_data):\n","    \"\"\"\n","        Decode a JPEG-encoded image to a uint8 tensor.\n","    \"\"\"\n","    image = tf.image.decode_jpeg(image_data, channels=3)\n","    return image\n","\n","def scale_image(image, label):\n","    \"\"\"\n","        Cast tensor to float and normalizes (range between 0 and 1).\n","    \"\"\"\n","    image = tf.cast(image, tf.float32)\n","    image /= 255.0\n","    return image, label\n","\n","def prepare_image(image, label):\n","    \"\"\"\n","        Resize and reshape images to the expected size.\n","    \"\"\"\n","    image = tf.image.resize(image, [HEIGHT_RS, WIDTH_RS])\n","    image = tf.reshape(image, [HEIGHT_RS, WIDTH_RS, 3])\n","    return image, label\n","\n","def read_tfrecord(example, labeled=True):\n","    \"\"\"\n","        1. Parse data based on the 'TFREC_FORMAT' map.\n","        2. Decode image.\n","        3. If 'labeled' returns (image, label) if not (image, name).\n","    \"\"\"\n","    if labeled:\n","        TFREC_FORMAT = {\n","            'image': tf.io.FixedLenFeature([], tf.string), \n","            'target': tf.io.FixedLenFeature([], tf.int64), \n","        }\n","    else:\n","        TFREC_FORMAT = {\n","            'image': tf.io.FixedLenFeature([], tf.string), \n","            'image_name': tf.io.FixedLenFeature([], tf.string), \n","        }\n","    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n","    image = decode_image(example['image'])\n","    if labeled:\n","        label_or_name = tf.cast(example['target'], tf.int32)\n","        # One-Hot Encoding needed to use \"categorical_crossentropy\" loss\n","        label_or_name = tf.one_hot(tf.cast(label_or_name, tf.int32), N_CLASSES)\n","    else:\n","        label_or_name = example['image_name']\n","    return image, label_or_name\n","\n","def get_dataset(FILENAMES, labeled=True, ordered=False, repeated=False, \n","                cached=False, augment=False):\n","    \"\"\"\n","        Return a Tensorflow dataset ready for training or inference.\n","    \"\"\"\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False\n","        dataset = tf.data.Dataset.list_files(FILENAMES)\n","        dataset = dataset.interleave(tf.data.TFRecordDataset, num_parallel_calls=AUTO)\n","    else:\n","        dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads=AUTO)\n","        \n","    dataset = dataset.with_options(ignore_order)\n","    \n","    dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled), num_parallel_calls=AUTO)\n","    \n","    if augment:\n","        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n","\n","    if repeated:\n","        dataset = dataset.repeat()\n","        \n","    dataset = dataset.batch(AUG_BATCH)\n","    if augment: \n","        dataset = dataset.map(transform, num_parallel_calls=AUTO) # note we put AFTER batching\n","    dataset = dataset.unbatch()\n","        \n","    dataset = dataset.map(scale_image, num_parallel_calls=AUTO)\n","    dataset = dataset.map(prepare_image, num_parallel_calls=AUTO)\n","    \n","    if not ordered:\n","        dataset = dataset.shuffle(2048)\n","    # if repeated:\n","    #     dataset = dataset.repeat()\n","        \n","    dataset = dataset.batch(BATCH_SIZE)\n","    \n","    if cached:\n","        dataset = dataset.cache()\n","    dataset = dataset.prefetch(AUTO)\n","\n","    return dataset\n","\n","def unfreeze_model(model):\n","    # Unfreeze layers while leaving BatchNorm layers frozen\n","    for layer in model.layers:\n","        if not isinstance(layer, L.BatchNormalization):\n","            layer.trainable = True\n","        else:\n","            layer.trainable = False\n","                \n","def unfreeze_block(model, block_name=None, n_top=3):\n","    # Unfreeze layers while leaving BatchNorm layers frozen\n","    for layer in model.layers[:-n_top]:\n","        if isinstance(layer, L.BatchNormalization):\n","            layer.trainable = False\n","        else:\n","            if block_name and (block_name in layer.name):\n","                layer.trainable = True"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:36.487403Z","iopub.status.busy":"2021-01-20T22:57:36.486600Z","iopub.status.idle":"2021-01-20T22:57:36.530480Z","shell.execute_reply":"2021-01-20T22:57:36.531039Z"},"id":"gHAxNOInCaO2","papermill":{"duration":0.081913,"end_time":"2021-01-20T22:57:36.531213","exception":false,"start_time":"2021-01-20T22:57:36.449300","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613126557619,"user_tz":-540,"elapsed":209523,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["# Visualization utility functions\n","np.set_printoptions(threshold=15, linewidth=80)\n","\n","def batch_to_numpy_images_and_labels(data):\n","    images, labels = data\n","    numpy_images = images.numpy()\n","    numpy_labels = labels.numpy()\n","    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n","        numpy_labels = [None for _ in enumerate(numpy_images)]\n","    # If no labels, only image IDs, return None for labels (this is the case for test data)\n","    return numpy_images, numpy_labels\n","\n","def title_from_label_and_target(label, correct_label):\n","    if correct_label is None:\n","        return CLASSES[label], True\n","    correct = (label == correct_label)\n","    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n","                                CLASSES[correct_label] if not correct else ''), correct\n","\n","def display_one_flower(image, title, subplot, red=False, titlesize=16):\n","    plt.subplot(*subplot)\n","    plt.axis('off')\n","    plt.imshow(image)\n","    if len(title) > 0:\n","        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', \n","                  fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n","    return (subplot[0], subplot[1], subplot[2]+1)\n","\n","def display_batch_of_images(databatch, predictions=None):\n","    \"\"\"This will work with:\n","    display_batch_of_images(images)\n","    display_batch_of_images(images, predictions)\n","    display_batch_of_images((images, labels))\n","    display_batch_of_images((images, labels), predictions)\n","    \"\"\"\n","    # data\n","    images, labels = batch_to_numpy_images_and_labels(databatch)\n","    labels = np.argmax(labels, axis=-1)\n","    if labels is None:\n","        labels = [None for _ in enumerate(images)]\n","        \n","    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n","    rows = int(math.sqrt(len(images)))\n","    cols = len(images)//rows\n","        \n","    # size and spacing\n","    FIGSIZE = 13.0\n","    SPACING = 0.1\n","    subplot=(rows,cols,1)\n","    if rows < cols:\n","        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n","    else:\n","        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n","    \n","    # display\n","    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n","        title = '' if label is None else CLASSES[label]\n","        correct = True\n","        if predictions is not None:\n","            title, correct = title_from_label_and_target(predictions[i], label)\n","        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n","        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n","    \n","    #layout\n","    plt.tight_layout()\n","    if label is None and predictions is None:\n","        plt.subplots_adjust(wspace=0, hspace=0)\n","    else:\n","        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n","    plt.show()\n","    \n","# Visualize model predictions\n","def dataset_to_numpy_util(dataset, N):\n","    dataset = dataset.unbatch().batch(N)\n","    for images, labels in dataset:\n","        numpy_images = images.numpy()\n","        numpy_labels = labels.numpy()\n","        break;  \n","    return numpy_images, numpy_labels\n","\n","def title_from_label_and_target(label, correct_label):\n","    label = np.argmax(label, axis=-1)\n","    correct = (label == correct_label)\n","    return \"{} [{}{}{}]\".format(label, str(correct), ', shoud be ' if not correct else '',\n","                                correct_label if not correct else ''), correct\n","\n","def display_one_flower_eval(image, title, subplot, red=False):\n","    plt.subplot(subplot)\n","    plt.axis('off')\n","    plt.imshow(image)\n","    plt.title(title, fontsize=14, color='red' if red else 'black')\n","    return subplot+1\n","\n","def display_9_images_with_predictions(images, predictions, labels):\n","    subplot=331\n","    plt.figure(figsize=(13,13))\n","    for i, image in enumerate(images):\n","        title, correct = title_from_label_and_target(predictions[i], labels[i])\n","        subplot = display_one_flower_eval(image, title, subplot, not correct)\n","        if i >= 8:\n","            break;\n","              \n","    plt.tight_layout()\n","    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n","    plt.show()\n","\n","\n","# Model evaluation\n","def plot_metrics(history):\n","    fig, axes = plt.subplots(2, 1, sharex='col', figsize=(20, 8))\n","    axes = axes.flatten()\n","    \n","    axes[0].plot(history['loss'], label='Train loss')\n","    axes[0].plot(history['val_loss'], label='Validation loss')\n","    axes[0].legend(loc='best', fontsize=16)\n","    axes[0].set_title('Loss')\n","    axes[0].axvline(np.argmin(history['loss']), linestyle='dashed')\n","    axes[0].axvline(np.argmin(history['val_loss']), linestyle='dashed', color='orange')\n","    \n","    axes[1].plot(history['accuracy'], label='Train accuracy')\n","    axes[1].plot(history['val_accuracy'], label='Validation accuracy')\n","    axes[1].legend(loc='best', fontsize=16)\n","    axes[1].set_title('Accuracy')\n","    axes[1].axvline(np.argmax(history['accuracy']), linestyle='dashed')\n","    axes[1].axvline(np.argmax(history['val_accuracy']), linestyle='dashed', color='orange')\n","\n","    plt.xlabel('Epochs', fontsize=16)\n","    sns.despine()\n","    plt.show()"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oCtCB3WdCaO2","papermill":{"duration":0.033127,"end_time":"2021-01-20T22:57:36.597612","exception":false,"start_time":"2021-01-20T22:57:36.564485","status":"completed"},"tags":[]},"source":["# Training data samples (with augmentation)"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:36.667226Z","iopub.status.busy":"2021-01-20T22:57:36.666549Z","iopub.status.idle":"2021-01-20T22:57:52.204000Z","shell.execute_reply":"2021-01-20T22:57:52.204539Z"},"id":"p8IMzXLRCaO2","papermill":{"duration":15.574028,"end_time":"2021-01-20T22:57:52.204708","exception":false,"start_time":"2021-01-20T22:57:36.630680","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1I1bZ6szcw5hVeqJd0SZq3Ll_bbAIhzk7"},"executionInfo":{"status":"ok","timestamp":1613126586340,"user_tz":-540,"elapsed":238240,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"de15d84e-2104-4c15-c765-baa18429bd52"},"source":["train_dataset = get_dataset(FILENAMES_COMP, ordered=True, augment=True)\n","train_iter = iter(train_dataset.unbatch().batch(20))\n","\n","display_batch_of_images(next(train_iter))\n","display_batch_of_images(next(train_iter))"],"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"HvXRzhofCaO5","papermill":{"duration":0.112509,"end_time":"2021-01-20T23:02:43.580615","exception":false,"start_time":"2021-01-20T23:02:43.468106","status":"completed"},"tags":[]},"source":["### Learning rate schedule\n","\n","We are going to use a `cosine learning rate schedule with a warm-up phase`, this may be a good idea since we are using a pre-trained model, the warm-up phase will be useful to avoid the pre-trained weights degradation resulting in catastrophic forgetting, during the schedule the learning rate will slowly decrease to very low values, this helps the model to land on more stable weights."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:02:43.808753Z","iopub.status.busy":"2021-01-20T23:02:43.807680Z","iopub.status.idle":"2021-01-20T23:02:47.940826Z","shell.execute_reply":"2021-01-20T23:02:47.939748Z"},"id":"I9cuJCl1CaO5","papermill":{"duration":4.248898,"end_time":"2021-01-20T23:02:47.940988","exception":false,"start_time":"2021-01-20T23:02:43.692090","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":422},"executionInfo":{"status":"ok","timestamp":1613126653764,"user_tz":-540,"elapsed":305660,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"82a5acd9-918e-4409-a606-83b8913a4246"},"source":["lr_start = 1e-8\n","lr_min = 1e-8\n","lr_max = LEARNING_RATE\n","num_cycles = 1.\n","warmup_epochs = 1\n","hold_max_epochs = 0\n","total_epochs = EPOCHS\n","warmup_steps = warmup_epochs * (NUM_TRAINING_IMAGES//BATCH_SIZE)\n","total_steps = total_epochs * (NUM_TRAINING_IMAGES//BATCH_SIZE)\n","\n","@tf.function\n","def lrfn(step):\n","    if step < warmup_steps:\n","        lr = (lr_max - lr_start) / warmup_steps * step + lr_start\n","    else:\n","        progress = (step - warmup_steps) / (total_steps - warmup_steps)\n","        lr = lr_max * (0.5 * (1.0 + tf.math.cos(np.pi * ((num_cycles * progress) % 1.0))))\n","        if lr_min is not None:\n","            lr = tf.math.maximum(lr_min, float(lr))\n","\n","    return lr\n","\n","\n","# rng = [i for i in range(total_epochs)]\n","rng = [i for i in range(total_steps)]\n","y = [lrfn(tf.cast(x, tf.float32)) for x in rng]\n","\n","sns.set(style='whitegrid')\n","fig, ax = plt.subplots(figsize=(20, 6))\n","plt.plot(rng, y)\n","\n","print(f'{total_steps} total steps and {NUM_TRAINING_IMAGES//BATCH_SIZE} steps per epoch')\n","print(f'Learning rate schedule: {y[0]:.3g} to {max(y):.3g} to {y[-1]:.3g}')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["11820 total steps and 591 steps per epoch\n","Learning rate schedule: 1e-08 to 8e-05 to 1e-08\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1440x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"OMIrA5jxCaO5","papermill":{"duration":0.112158,"end_time":"2021-01-20T23:02:48.166235","exception":false,"start_time":"2021-01-20T23:02:48.054077","status":"completed"},"tags":[]},"source":["# Model"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:02:48.402810Z","iopub.status.busy":"2021-01-20T23:02:48.402111Z","iopub.status.idle":"2021-01-20T23:02:48.406439Z","shell.execute_reply":"2021-01-20T23:02:48.405740Z"},"id":"pRksD6K6CaO5","papermill":{"duration":0.126526,"end_time":"2021-01-20T23:02:48.406566","exception":false,"start_time":"2021-01-20T23:02:48.280040","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613126653765,"user_tz":-540,"elapsed":305658,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["def model_fn(input_shape, N_CLASSES):\n","    inputs = L.Input(shape=input_shape, name='input_image')\n","    base_model = efn.EfficientNetB7(input_tensor=inputs, \n","                                    include_top=False, \n","                                    weights='noisy-student', \n","                                    pooling='avg')\n","    base_model.trainable = False\n","    x = L.Dropout(.5)(base_model.output)\n","    output = L.Dense(N_CLASSES, activation='softmax', name='output')(x)\n","    model = Model(inputs=inputs, outputs=output)\n","\n","    return model"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:02:48.640007Z","iopub.status.busy":"2021-01-20T23:02:48.638735Z","iopub.status.idle":"2021-01-20T23:02:48.642985Z","shell.execute_reply":"2021-01-20T23:02:48.643690Z"},"id":"4zl0qy-pcR-A","papermill":{"duration":0.122772,"end_time":"2021-01-20T23:02:48.643846","exception":false,"start_time":"2021-01-20T23:02:48.521074","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613126653766,"user_tz":-540,"elapsed":305656,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["#help(strategy)"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hMc0tk0VCaO5","papermill":{"duration":0.114465,"end_time":"2021-01-20T23:02:48.871581","exception":false,"start_time":"2021-01-20T23:02:48.757116","status":"completed"},"tags":[]},"source":["# Training"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:02:49.104256Z","iopub.status.busy":"2021-01-20T23:02:49.103030Z","iopub.status.idle":"2021-01-20T23:41:32.330134Z","shell.execute_reply":"2021-01-20T23:41:32.329366Z"},"id":"8HrFGFRNCaO5","papermill":{"duration":2323.344808,"end_time":"2021-01-20T23:41:32.330270","exception":false,"start_time":"2021-01-20T23:02:48.985462","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e2a4e491-12f4-485e-a60e-f19642ee86f9"},"source":["skf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n","oof_pred = []; oof_labels = []; history_list = []\n","\n","for fold,(idxT, idxV) in enumerate(skf.split(np.arange(50))):\n","    if fold >= FOLDS_USED:\n","        break\n","    if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n","    K.clear_session()\n","    print(f'\\nFOLD: {fold+1}')\n","    print(f'TRAIN: {idxT} VALID: {idxV}')\n","\n","    # Create train and validation sets\n","    FILENAMES_COMP = tf.io.gfile.glob([GCS_PATH + '/Id_train%.2i*.tfrec' % x for x in idxT])\n","    # FILENAMES_2019 = tf.io.gfile.glob([GCS_PATH_EXT + '/Id_train%.2i*.tfrec' % x for x in idxT])\n","\n","    FILENAMES_COMP_CBB = tf.io.gfile.glob([GCS_PATH_CLASSES + '/CBB%.2i*.tfrec' % x for x in idxT])\n","    FILENAMES_COMP_CBSD = tf.io.gfile.glob([GCS_PATH_CLASSES + '/CBSD%.2i*.tfrec' % x for x in idxT])\n","    FILENAMES_COMP_CGM = tf.io.gfile.glob([GCS_PATH_CLASSES + '/CGM%.2i*.tfrec' % x for x in idxT])\n","    FILENAMES_COMP_Healthy = tf.io.gfile.glob([GCS_PATH_CLASSES + '/Healthy%.2i*.tfrec' % x for x in idxT])\n","    \n","    # FILENAMES_2019_CBB = tf.io.gfile.glob([GCS_PATH_EXT_CLASSES + '/CBB%.2i*.tfrec' % x for x in idxT])\n","    # FILENAMES_2019_CBSD = tf.io.gfile.glob([GCS_PATH_EXT_CLASSES + '/CBSD%.2i*.tfrec' % x for x in idxT])\n","    # FILENAMES_2019_CGM = tf.io.gfile.glob([GCS_PATH_EXT_CLASSES + '/CGM%.2i*.tfrec' % x for x in idxT])\n","    # FILENAMES_2019_Healthy = tf.io.gfile.glob([GCS_PATH_EXT_CLASSES + '/Healthy%.2i*.tfrec' % x for x in idxT])\n","\n","    TRAIN_FILENAMES = (FILENAMES_COMP + \n","                      #  FILENAMES_2019 + \n","                       (2 * FILENAMES_COMP_CBB) + \n","                      #  (2 * FILENAMES_2019_CBB) + \n","                       (2 * FILENAMES_COMP_CBSD) + \n","                      #  (2 * FILENAMES_2019_CBSD) + \n","                       (2 * FILENAMES_COMP_CGM) + \n","                      #  (2 * FILENAMES_2019_CGM) + \n","                       (2 * FILENAMES_COMP_Healthy))\n","                      #  (2 * FILENAMES_2019_Healthy))\n","    \n","    VALID_FILENAMES = tf.io.gfile.glob([GCS_PATH + '/Id_train%.2i*.tfrec' % x for x in idxV])\n","    np.random.shuffle(TRAIN_FILENAMES)\n","    \n","    ct_train = count_data_items(TRAIN_FILENAMES)\n","    ct_valid = count_data_items(VALID_FILENAMES)\n","    \n","    step_size = (ct_train // BATCH_SIZE)\n","    valid_step_size = (ct_valid // BATCH_SIZE)\n","    total_steps=(total_epochs * step_size)\n","    warmup_steps=(warmup_epochs * step_size)\n","    \n","    \n","    # Build TF datasets\n","    train_ds = strategy.experimental_distribute_dataset(get_dataset(TRAIN_FILENAMES, repeated=True, augment=True))\n","    valid_ds = strategy.experimental_distribute_dataset(get_dataset(VALID_FILENAMES, ordered=True, repeated=True, cached=True))\n","    train_data_iter = iter(train_ds)\n","    valid_data_iter = iter(valid_ds)\n","    \n","    \n","    # Step functions\n","    @tf.function\n","    def train_step(data_iter):\n","        def train_step_fn(x, y):\n","            with tf.GradientTape() as tape:\n","                probabilities = model(x, training=True)\n","                loss = loss_fn(y, probabilities, label_smoothing=.3)\n","            gradients = tape.gradient(loss, model.trainable_variables)\n","            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","            # update metrics\n","            train_accuracy.update_state(y, probabilities)\n","            train_loss.update_state(loss)\n","        for _ in tf.range(step_size):\n","            if COLAB:\n","                #print(COLAB)\n","                strategy.experimental_run_v2(train_step_fn, next(data_iter))\n","            else:\n","                strategy.experimental_run_v2(train_step_fn, next(data_iter))\n","\n","    @tf.function\n","    def valid_step(data_iter):\n","        def valid_step_fn(x, y):\n","            probabilities = model(x, training=False)\n","            loss = loss_fn(y, probabilities)\n","            # update metrics\n","            valid_accuracy.update_state(y, probabilities)\n","            valid_loss.update_state(loss)\n","        for _ in tf.range(valid_step_size):\n","            if COLAB:\n","                strategy.experimental_run_v2(valid_step_fn, next(data_iter))\n","            else:\n","                strategy.experimental_run_v2(valid_step_fn, next(data_iter))\n","    \n","    \n","    # Model\n","    model_path = models_path+f'model_{fold}.h5'\n","    with strategy.scope():\n","        model = model_fn((None, None, CHANNELS), N_CLASSES)\n","        unfreeze_model(model) # unfreeze all layers except \"batch normalization\"\n","        \n","        optimizer = optimizers.Adam(learning_rate=lambda: lrfn(tf.cast(optimizer.iterations, tf.float32)))\n","        loss_fn = losses.categorical_crossentropy\n","\n","        train_accuracy = metrics.CategoricalAccuracy()\n","        valid_accuracy = metrics.CategoricalAccuracy()\n","        train_loss = metrics.Sum()\n","        valid_loss = metrics.Sum()\n","    \n","    \n","    # Setup training loop\n","    step = 0\n","    epoch_steps = 0\n","    patience_cnt = 0\n","    best_val = 0\n","    history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}\n","\n","    ### Train model\n","    for epoch in range(EPOCHS):\n","        epoch_start_time = time.time()\n","\n","        # Run training step\n","        train_step(train_data_iter)\n","        epoch_steps += step_size\n","        step += step_size\n","            \n","\n","        # Validation run at the end of each epoch\n","        if (step // step_size) > epoch:\n","            # Validation run\n","            valid_epoch_steps = 0\n","            valid_step(valid_data_iter)\n","            valid_epoch_steps += valid_step_size\n","\n","            # Compute metrics\n","            history['accuracy'].append(train_accuracy.result().numpy())\n","            history['loss'].append(train_loss.result().numpy() / (BATCH_SIZE * epoch_steps))\n","            history['val_accuracy'].append(valid_accuracy.result().numpy())\n","            history['val_loss'].append(valid_loss.result().numpy() / (BATCH_SIZE * valid_epoch_steps))\n","\n","            # Report metrics\n","            epoch_time = time.time() - epoch_start_time\n","            print(f'\\nEPOCH {epoch+1}/{EPOCHS}')\n","            print(f'time: {epoch_time:0.1f}s',\n","                  f\"loss: {history['loss'][-1]:0.4f}\",\n","                  f\"accuracy: {history['accuracy'][-1]:0.4f}\",\n","                  f\"val_loss: {history['val_loss'][-1]:0.4f}\",\n","                  f\"val_accuracy: {history['val_accuracy'][-1]:0.4f}\",\n","                  f'lr: {lrfn(tf.cast(optimizer.iterations, tf.int32).numpy()):0.4g}')\n","\n","            # Early stopping monitor\n","            if history['val_accuracy'][-1] >= best_val:\n","                best_val = history['val_accuracy'][-1]\n","                model.save_weights(model_path)\n","                print(f'Saved model weights at \"{model_path}\"')\n","                patience_cnt = 1\n","            else:\n","                patience_cnt += 1\n","            # if patience_cnt > ES_PATIENCE:\n","            #     print(f'Epoch {epoch:05d}: early stopping')\n","            #     break\n","\n","                \n","            # Set up next epoch\n","            epoch = step // step_size\n","            epoch_steps = 0\n","            train_accuracy.reset_states()\n","            train_loss.reset_states()\n","            valid_accuracy.reset_states()\n","            valid_loss.reset_states()\n","    \n","    \n","    ### RESULTS\n","    print(f\"#### FOLD {fold+1} OOF Accuracy = {np.max(history['val_accuracy']):.3f}\")\n","    \n","    history_list.append(history)\n","    # Load best model weights\n","    model.load_weights(model_path)\n","\n","    # OOF predictions\n","    ds_valid = get_dataset(VALID_FILENAMES, ordered=True)\n","    oof_labels.append([target.numpy() for img, target in iter(ds_valid.unbatch())])\n","    x_oof = ds_valid.map(lambda image, target: image)\n","    oof_pred.append(np.argmax(model.predict(x_oof), axis=-1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.84.237.202:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.84.237.202:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.84.237.202:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.84.237.202:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","FOLD: 1\n","TRAIN: [ 0  1  3 ... 47 48 49] VALID: [ 2  4 10 11 22 27 28 31 38 41]\n","Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b7_noisy-student_notop.h5\n","258072576/258068648 [==============================] - 4s 0us/step\n","WARNING:tensorflow:From <ipython-input-23-dfb847e1919a>:71: StrategyBase.experimental_run_v2 (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","renamed to `run`\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-23-dfb847e1919a>:71: StrategyBase.experimental_run_v2 (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","renamed to `run`\n"],"name":"stderr"},{"output_type":"stream","text":["\n","EPOCH 1/20\n","time: 439.1s loss: 1.4168 accuracy: 0.5228 val_loss: 0.7247 val_accuracy: 0.8295 lr: 8e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 2/20\n","time: 198.9s loss: 1.2616 accuracy: 0.7217 val_loss: 0.6456 val_accuracy: 0.8712 lr: 7.945e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 3/20\n","time: 199.0s loss: 1.2367 accuracy: 0.7440 val_loss: 0.7023 val_accuracy: 0.8636 lr: 7.783e-05\n","\n","EPOCH 4/20\n","WARNING:tensorflow:5 out of the last 389 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 389 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 199.1s loss: 1.2237 accuracy: 0.7540 val_loss: 0.6835 val_accuracy: 0.8762 lr: 7.518e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 5/20\n","WARNING:tensorflow:6 out of the last 390 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 390 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 199.1s loss: 1.2100 accuracy: 0.7660 val_loss: 0.5982 val_accuracy: 0.8892 lr: 7.157e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 6/20\n","WARNING:tensorflow:7 out of the last 391 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 391 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 199.2s loss: 1.2041 accuracy: 0.7726 val_loss: 0.6125 val_accuracy: 0.8866 lr: 6.709e-05\n","\n","EPOCH 7/20\n","WARNING:tensorflow:8 out of the last 392 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 392 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 199.4s loss: 1.1967 accuracy: 0.7811 val_loss: 0.6305 val_accuracy: 0.8925 lr: 6.188e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 8/20\n","WARNING:tensorflow:9 out of the last 393 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 393 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 199.2s loss: 1.1938 accuracy: 0.7890 val_loss: 0.6398 val_accuracy: 0.8847 lr: 5.607e-05\n","\n","EPOCH 9/20\n","WARNING:tensorflow:10 out of the last 394 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 394 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 199.6s loss: 1.1796 accuracy: 0.7972 val_loss: 0.6212 val_accuracy: 0.8873 lr: 4.982e-05\n","\n","EPOCH 10/20\n","WARNING:tensorflow:11 out of the last 395 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 395 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 199.2s loss: 1.1790 accuracy: 0.8004 val_loss: 0.6337 val_accuracy: 0.8840 lr: 4.33e-05\n","\n","EPOCH 11/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 199.3s loss: 1.1675 accuracy: 0.8105 val_loss: 0.5731 val_accuracy: 0.8892 lr: 3.67e-05\n","\n","EPOCH 12/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 199.2s loss: 1.1702 accuracy: 0.8067 val_loss: 0.5988 val_accuracy: 0.8890 lr: 3.018e-05\n","\n","EPOCH 13/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 200.3s loss: 1.1615 accuracy: 0.8166 val_loss: 0.6114 val_accuracy: 0.8897 lr: 2.393e-05\n","\n","EPOCH 14/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 199.9s loss: 1.1594 accuracy: 0.8184 val_loss: 0.6176 val_accuracy: 0.8857 lr: 1.812e-05\n","\n","EPOCH 15/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 200.0s loss: 1.1559 accuracy: 0.8256 val_loss: 0.6174 val_accuracy: 0.8897 lr: 1.291e-05\n","\n","EPOCH 16/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 200.2s loss: 1.1553 accuracy: 0.8266 val_loss: 0.6114 val_accuracy: 0.8892 lr: 8.434e-06\n","\n","EPOCH 17/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 200.5s loss: 1.1500 accuracy: 0.8295 val_loss: 0.5939 val_accuracy: 0.8937 lr: 4.821e-06\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 18/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 200.5s loss: 1.1499 accuracy: 0.8282 val_loss: 0.5856 val_accuracy: 0.8939 lr: 2.167e-06\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 19/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 201.3s loss: 1.1468 accuracy: 0.8346 val_loss: 0.5787 val_accuracy: 0.8965 lr: 5.455e-07\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 20/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7f6e638b07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 201.1s loss: 1.1547 accuracy: 0.8286 val_loss: 0.5965 val_accuracy: 0.8925 lr: 8e-05\n","#### FOLD 1 OOF Accuracy = 0.897\n","WARNING:tensorflow:TPU system grpc://10.84.237.202:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.84.237.202:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.84.237.202:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.84.237.202:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","FOLD: 2\n","TRAIN: [ 0  1  2 ... 46 47 49] VALID: [ 7 14 18 26 29 33 34 35 45 48]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NQyHtXnRCaO5","papermill":{"duration":0.130935,"end_time":"2021-01-20T23:41:32.592224","exception":false,"start_time":"2021-01-20T23:41:32.461289","status":"completed"},"tags":[]},"source":["## Model loss graph"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:41:32.862698Z","iopub.status.busy":"2021-01-20T23:41:32.861475Z","iopub.status.idle":"2021-01-20T23:41:35.936240Z","shell.execute_reply":"2021-01-20T23:41:35.935506Z"},"id":"_7pUdch3CaO6","papermill":{"duration":3.212527,"end_time":"2021-01-20T23:41:35.936368","exception":false,"start_time":"2021-01-20T23:41:32.723841","status":"completed"},"tags":[]},"source":["for fold, history in enumerate(history_list):\n","    print(f'\\nFOLD: {fold+1}')\n","    plot_metrics(history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ImheYrtKCaO7","papermill":{"duration":0.140565,"end_time":"2021-01-20T23:41:36.235070","exception":false,"start_time":"2021-01-20T23:41:36.094505","status":"completed"},"tags":[]},"source":["# Model evaluation\n","\n","Now we can evaluate the performance of the model, first, we can evaluate the usual metrics like, `accuracy`, `precision`, `recall`, and `f1-score`, `scikit-learn` provides the perfect function for this `classification_report`.\n","\n","We are evaluating the model on the `OOF` predictions, it stands for `Out Of Fold`, since we are training using `K-Fold` our model will see all the data, and the correct way to evaluate each fold is by looking at the predictions that are not from that fold.\n","\n","## OOF metrics"]},{"cell_type":"markdown","metadata":{"id":"I_QvO8rPCaO7","papermill":{"duration":0.142773,"end_time":"2021-01-20T23:41:36.524904","exception":false,"start_time":"2021-01-20T23:41:36.382131","status":"completed"},"tags":[]},"source":["#### I am still having some problems to get the real model `OOF` scores while using `TPU Pods`, so the results here and the confusion matrix are just placeholders."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:41:36.817847Z","iopub.status.busy":"2021-01-20T23:41:36.816550Z","iopub.status.idle":"2021-01-20T23:41:36.871365Z","shell.execute_reply":"2021-01-20T23:41:36.870279Z"},"id":"q7TfhkICCaO7","papermill":{"duration":0.205034,"end_time":"2021-01-20T23:41:36.871548","exception":false,"start_time":"2021-01-20T23:41:36.666514","status":"completed"},"tags":[]},"source":["y_true = np.concatenate(oof_labels)\n","y_true = np.argmax(y_true, axis=-1)\n","y_pred = np.concatenate(oof_pred)\n","\n","print(classification_report(y_true, y_pred, target_names=CLASSES))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pIAJafCnCaO7","papermill":{"duration":0.1407,"end_time":"2021-01-20T23:41:37.153525","exception":false,"start_time":"2021-01-20T23:41:37.012825","status":"completed"},"tags":[]},"source":["# Confusion matrix\n","\n","Let's also take a look at the confusion matrix, this will give us an idea about what classes the model is mixing or having a hard time."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:41:37.451948Z","iopub.status.busy":"2021-01-20T23:41:37.451220Z","iopub.status.idle":"2021-01-20T23:41:37.902193Z","shell.execute_reply":"2021-01-20T23:41:37.902770Z"},"id":"dw2F8Wk2CaO7","papermill":{"duration":0.608362,"end_time":"2021-01-20T23:41:37.902957","exception":false,"start_time":"2021-01-20T23:41:37.294595","status":"completed"},"tags":[]},"source":["fig, ax = plt.subplots(1, 1, figsize=(20, 12))\n","cfn_matrix = confusion_matrix(y_true, y_pred, labels=range(len(CLASSES)))\n","cfn_matrix = (cfn_matrix.T / cfn_matrix.sum(axis=1)).T\n","df_cm = pd.DataFrame(cfn_matrix, index=CLASSES, columns=CLASSES)\n","ax = sns.heatmap(df_cm, cmap='Blues', annot=True, fmt='.2f', linewidths=.5).set_title('Train', fontsize=30)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AaZVX_ZhCaO7","papermill":{"duration":0.14275,"end_time":"2021-01-20T23:41:38.189478","exception":false,"start_time":"2021-01-20T23:41:38.046728","status":"completed"},"tags":[]},"source":["# Visualize predictions\n","\n","Finally, it is a good practice to always inspect some of the model's prediction by looking at the data, this can give an idea if the model is getting some predictions wrong because the data is really hard, of if it is because the model is actually bad.\n","\n","\n","### Class map\n","```\n","0: Cassava Bacterial Blight (CBB)\n","1: Cassava Brown Streak Disease (CBSD)\n","2: Cassava Green Mottle (CGM)\n","3: Cassava Mosaic Disease (CMD)\n","4: Healthy\n","```\n","\n","\n","## Train set"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:41:38.486711Z","iopub.status.busy":"2021-01-20T23:41:38.478610Z","iopub.status.idle":"2021-01-20T23:42:07.973278Z","shell.execute_reply":"2021-01-20T23:42:07.973946Z"},"id":"ExEWWtxyCaO8","papermill":{"duration":29.642469,"end_time":"2021-01-20T23:42:07.974121","exception":false,"start_time":"2021-01-20T23:41:38.331652","status":"completed"},"tags":[]},"source":["train_dataset = get_dataset(TRAINING_FILENAMES, ordered=True)\n","x_samp, y_samp = dataset_to_numpy_util(train_dataset, 18)\n","y_samp = np.argmax(y_samp, axis=-1)\n","\n","x_samp_1, y_samp_1 = x_samp[:9,:,:,:], y_samp[:9]\n","samp_preds_1 = model.predict(x_samp_1, batch_size=9)\n","display_9_images_with_predictions(x_samp_1, samp_preds_1, y_samp_1)\n","\n","x_samp_2, y_samp_2 = x_samp[9:,:,:,:], y_samp[9:]\n","samp_preds_2 = model.predict(x_samp_2, batch_size=9)\n","display_9_images_with_predictions(x_samp_2, samp_preds_2, y_samp_2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:42:08.485006Z","iopub.status.busy":"2021-01-20T23:42:08.479584Z","iopub.status.idle":"2021-01-20T23:42:08.490084Z","shell.execute_reply":"2021-01-20T23:42:08.489432Z"},"id":"h9CeTJAYKYQd","papermill":{"duration":0.271568,"end_time":"2021-01-20T23:42:08.490212","exception":false,"start_time":"2021-01-20T23:42:08.218644","status":"completed"},"tags":[]},"source":["\n","save_data=True# You can immediately create a kaggle dataset from your models\n","if COLAB and save_data:\n","  \n","    import json\n","\n","\n","    \n","    data = {\"title\": \"Cassava Leaf Disease\", \n","        \"id\": \"aikhmelnytskyy/CassavaLeafDisease\", \n","        \"licenses\": [\n","                     {\n","                         \"name\": \"CC0-1.0\"\n","                      }\n","                     ]}\n","    \n","\n","    # for kaggle api Connection\n","    \n","    !kaggle datasets init -p /content/drive/MyDrive/Colab Notebooks/Cassava/\n","    \n","    with open(\"/content/drive/MyDrive/Colab Notebooks/Cassava/dataset-metadata.json\", \"w\", encoding=\"utf-8\") as file:\n","        json.dump(data, file)\n","    \n","    #if new dataset\n","    !kaggle datasets create -p /content/drive/MyDrive/Models/Cassava/\n","    #If you’d like to upload a new version of an existing dataset\n","    #!kaggle datasets version -p /content/drive/MyDrive/Models/Cassava/ -m \"Your message here\""],"execution_count":null,"outputs":[]}]}