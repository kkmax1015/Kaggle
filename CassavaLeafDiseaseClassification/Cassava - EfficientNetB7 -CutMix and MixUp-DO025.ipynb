{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"papermill":{"duration":2705.650201,"end_time":"2021-01-20T23:42:08.938285","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-01-20T22:57:03.288084","version":"2.1.0"},"colab":{"name":"Cassava - EfficientNetB7 -CutMix and MixUp-DO025.ipynb","provenance":[{"file_id":"1ZgPO3NjZoFnZRA9GQ03bBGBmT3B1kHVw","timestamp":1613208175675},{"file_id":"1-ZoJbdw3oWULsug_imAutWQbucAV1_f-","timestamp":1612628699360},{"file_id":"1k3GJEDIw5B9smNhmCO9z5wJn0_fz7V6e","timestamp":1612360146025},{"file_id":"1luIn2wZfy_fopw5CZhO7tSwz3QfPBeu0","timestamp":1611649047226},{"file_id":"14lxnkhkxhL-leLaM7_ewQrCSbDr617ZZ","timestamp":1611576808109}],"collapsed_sections":[]},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:08.648534Z","iopub.status.busy":"2021-01-20T22:57:08.647654Z","iopub.status.idle":"2021-01-20T22:57:08.650554Z","shell.execute_reply":"2021-01-20T22:57:08.651069Z"},"papermill":{"duration":0.038327,"end_time":"2021-01-20T22:57:08.651252","exception":false,"start_time":"2021-01-20T22:57:08.612925","status":"completed"},"tags":[],"id":"BkVGwREBxGQy","executionInfo":{"status":"ok","timestamp":1613280899710,"user_tz":-540,"elapsed":657,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["EPOCHS = 20 \n","HEIGHT = 512\n","WIDTH = 512\n","HEIGHT_RS = 512\n","WIDTH_RS = 512\n","CHANNELS = 3\n","N_CLASSES = 5\n","N_FOLDS = 5\n","FOLDS_USED = 5\n","ES_PATIENCE = 5\n","IMAGE_SIZE = [512, 512]"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:08.738880Z","iopub.status.busy":"2021-01-20T22:57:08.723182Z","iopub.status.idle":"2021-01-20T22:57:11.217685Z","shell.execute_reply":"2021-01-20T22:57:11.216355Z"},"id":"YZBauHrJCkn7","papermill":{"duration":2.537229,"end_time":"2021-01-20T22:57:11.217823","exception":false,"start_time":"2021-01-20T22:57:08.680594","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613281070376,"user_tz":-540,"elapsed":171309,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"e93dd0eb-3979-4a59-b6c0-031f3fd590d9"},"source":["\n","import os\n","\n","models_path=''\n","\n","\n","\n","\n","\n","COLAB=True\n","import gc\n","!pip install fsspec\n","!pip install gcsfs \n","!pip install --upgrade --force-reinstall --no-deps kaggle\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/MyDrive/Colab Notebooks/Cassava/'\n","\n","#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","\n","database_base_path = 'gs://kds-9254a9aba4b37289f07bbbbe4e2af5c952dd2d811a2c823340ca8091'\n","GCS_PATH = 'gs://kds-73ad24bb2e88a88d616d183727bf88d16deab7892840afc75a21cc90'\n","GCS_PATH_EXT = 'gs://kds-45c6060e9b2c39c0152e5fb66610110218c984e18c09a40d3f7b23d0'\n","GCS_PATH_CLASSES = 'gs://kds-214b31c2a1f93777a325b30beb67b72cda39e60b413aeaa16bff7396'\n","GCS_PATH_EXT_CLASSES = 'gs://kds-46c36b9b602c0da9228d8da71233604d6a4d98c9b36e7e9598d3dceb'\n","\n","\n","# \n","#This is a path to a dataset that changes over time, so you need to constantly update it. To update the path just run the code: \n","#GCS_DS_PATH = KaggleDatasets (). Get_gcs_path ()\n","#print (GCS_PATH)......\n","models_path='/content/drive/MyDrive/Colab Notebooks/Cassava/model/'# I created a folder called Models/Cassava on my Google Drive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting fsspec\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/80/72ac0982cc833945fada4b76c52f0f65435ba4d53bc9317d1c70b5f7e7d5/fsspec-0.8.5-py3-none-any.whl (98kB)\n","\r\u001b[K     |███▎                            | 10kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 20kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 51kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 71kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 4.2MB/s \n","\u001b[?25hInstalling collected packages: fsspec\n","Successfully installed fsspec-0.8.5\n","Collecting gcsfs\n","  Downloading https://files.pythonhosted.org/packages/ef/7a/c847e1a170be1836d8df2d3e0449b349b06c90a627914196e084b75b0284/gcsfs-0.7.2-py2.py3-none-any.whl\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.23.0)\n","Requirement already satisfied: fsspec>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.8.5)\n","Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.25.0)\n","Collecting aiohttp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/e6/d4b6235d776c9b33f853e603efede5aac5a34f71ca9d3877adb30492eb4e/aiohttp-3.7.3-cp36-cp36m-manylinux2014_x86_64.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 7.7MB/s \n","\u001b[?25hRequirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.10)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (53.0.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.7)\n","Collecting idna-ssl>=1.0; python_version < \"3.7\"\n","  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n","Collecting async-timeout<4.0,>=3.0\n","  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n","Collecting yarl<2.0,>=1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/08/52b26b44bce7b818b410aee37c5e424c9ea420c557bca97dc2adac29b151/yarl-1.6.3-cp36-cp36m-manylinux2014_x86_64.whl (293kB)\n","\u001b[K     |████████████████████████████████| 296kB 22.5MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/35/b22524d6b9cacfb4c5eff413a069bbc17c6ea628e54da5c6c989998ced5f/multidict-5.1.0-cp36-cp36m-manylinux2014_x86_64.whl (141kB)\n","\u001b[K     |████████████████████████████████| 143kB 25.3MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (20.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (3.7.4.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n","Building wheels for collected packages: idna-ssl\n","  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3163 sha256=8c56617d665fb7230096fc107013ebcb8a4cacc69bab9d5955c43e0debaf5374\n","  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n","Successfully built idna-ssl\n","Installing collected packages: idna-ssl, async-timeout, multidict, yarl, aiohttp, gcsfs\n","Successfully installed aiohttp-3.7.3 async-timeout-3.0.1 gcsfs-0.7.2 idna-ssl-1.1.0 multidict-5.1.0 yarl-1.6.3\n","Collecting kaggle\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/33/365c0d13f07a2a54744d027fe20b60dacdfdfb33bc04746db6ad0b79340b/kaggle-1.5.10.tar.gz (59kB)\n","\u001b[K     |████████████████████████████████| 61kB 3.8MB/s \n","\u001b[?25hBuilding wheels for collected packages: kaggle\n","  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaggle: filename=kaggle-1.5.10-cp36-none-any.whl size=73269 sha256=d50778102facf48efa40b196daa90fd6a316487c7bbeec966986c5834ada7336\n","  Stored in directory: /root/.cache/pip/wheels/3a/d1/7e/6ce09b72b770149802c653a02783821629146983ee5a360f10\n","Successfully built kaggle\n","Installing collected packages: kaggle\n","  Found existing installation: kaggle 1.5.10\n","    Uninstalling kaggle-1.5.10:\n","      Successfully uninstalled kaggle-1.5.10\n","Successfully installed kaggle-1.5.10\n","Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/Cassava\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:11.294556Z","iopub.status.busy":"2021-01-20T22:57:11.290187Z","iopub.status.idle":"2021-01-20T22:57:11.298693Z","shell.execute_reply":"2021-01-20T22:57:11.298011Z"},"id":"5V15UaoACh-M","papermill":{"duration":0.051661,"end_time":"2021-01-20T22:57:11.298873","exception":false,"start_time":"2021-01-20T22:57:11.247212","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613281070544,"user_tz":-540,"elapsed":171469,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["if COLAB:# Prepare the kaggle.json file for use \n","    from google.colab import files\n","    if not os.path.exists('/content/drive/MyDrive/Colab Notebooks/.kaggle/kaggle.json'):\n","        !mkdir ~/content/drive/MyDrive/Colab Notebooks/.kaggle/\n","        if not os.path.exists('/content/drive/MyDrive/Colab Notebooks/.kaggle/kaggle.json'):\n","            files.upload()\n","            !cp kaggle.json ~/content/drive/MyDrive/Colab Notebooks/.kaggle/\n","        else:\n","            !cp '/content/drive/MyDrive/Colab Notebooks/' ~/.kaggle/  \n","        !chmod 600 ~/content/drive/MyDrive/Colab Notebooks/.kaggle/kaggle.json\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:11.368941Z","iopub.status.busy":"2021-01-20T22:57:11.367797Z","iopub.status.idle":"2021-01-20T22:57:11.371432Z","shell.execute_reply":"2021-01-20T22:57:11.370752Z"},"id":"urYjsB4IV-t5","papermill":{"duration":0.04238,"end_time":"2021-01-20T22:57:11.371550","exception":false,"start_time":"2021-01-20T22:57:11.329170","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613281192050,"user_tz":-540,"elapsed":292969,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"bbe076c6-799f-45cc-edc5-3c2766f6a3e2"},"source":["if COLAB:# force TF to 2.2\n","    !pip install -q tensorflow~=2.2.0 tensorflow_gcs_config~=2.2.0\n","    \n","    import requests\n","    import os\n","    import tensorflow as tf\n","    resp = requests.post(\"http://{}:8475/requestversion/{}\".format(os.environ[\"COLAB_TPU_ADDR\"].split(\":\")[0], tf.__version__))\n","    if resp.status_code != 200:\n","      print(\"Failed to switch the TPU to TF {}\".format(version))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 516.2MB 28kB/s \n","\u001b[K     |████████████████████████████████| 399kB 54.7MB/s \n","\u001b[K     |████████████████████████████████| 3.0MB 34.6MB/s \n","\u001b[K     |████████████████████████████████| 20.1MB 1.4MB/s \n","\u001b[K     |████████████████████████████████| 460kB 46.1MB/s \n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DJLH967uCaOv","papermill":{"duration":0.029839,"end_time":"2021-01-20T22:57:11.431128","exception":false,"start_time":"2021-01-20T22:57:11.401289","status":"completed"},"tags":[]},"source":["## Dependencies"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:11.498391Z","iopub.status.busy":"2021-01-20T22:57:11.497630Z","iopub.status.idle":"2021-01-20T22:57:21.909368Z","shell.execute_reply":"2021-01-20T22:57:21.908714Z"},"id":"u8lneueOCaOv","papermill":{"duration":10.446497,"end_time":"2021-01-20T22:57:21.909508","exception":false,"start_time":"2021-01-20T22:57:11.463011","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613281195487,"user_tz":-540,"elapsed":296396,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"f30a9e2d-06c4-44b0-b8bc-ebd2bde6e077"},"source":["!pip install --quiet efficientnet"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |██████▌                         | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.1MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:21.982695Z","iopub.status.busy":"2021-01-20T22:57:21.981961Z","iopub.status.idle":"2021-01-20T22:57:29.891530Z","shell.execute_reply":"2021-01-20T22:57:29.890624Z"},"id":"-iMoIRz7CaOw","papermill":{"duration":7.952124,"end_time":"2021-01-20T22:57:29.891659","exception":false,"start_time":"2021-01-20T22:57:21.939535","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613281196723,"user_tz":-540,"elapsed":297626,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["import math, os, re, warnings, random, time\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import classification_report, confusion_matrix\n","import tensorflow as tf\n","import tensorflow.keras.layers as L\n","import tensorflow.keras.backend as K\n","from tensorflow.keras import optimizers, Sequential, losses, metrics, Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","import efficientnet.tfkeras as efn\n","\n","def seed_everything(seed=0):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","seed = 0\n","seed_everything(seed)\n","warnings.filterwarnings('ignore')"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z-146lSGCaOx","papermill":{"duration":0.030316,"end_time":"2021-01-20T22:57:29.954488","exception":false,"start_time":"2021-01-20T22:57:29.924172","status":"completed"},"tags":[]},"source":["### Hardware configuration\n","\n","Note that we have `32` cores, this is because the `TPU v2 Pod` have more cores than a single `TPU v3` which has `8` cores."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:30.071569Z","iopub.status.busy":"2021-01-20T22:57:30.035804Z","iopub.status.idle":"2021-01-20T22:57:34.008561Z","shell.execute_reply":"2021-01-20T22:57:34.010162Z"},"id":"cCFwEwkVCaOy","papermill":{"duration":4.024986,"end_time":"2021-01-20T22:57:34.010410","exception":false,"start_time":"2021-01-20T22:57:29.985424","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613281221156,"user_tz":-540,"elapsed":322052,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"45ce0221-c99d-4942-fc58-4f242b73f3c6"},"source":["# TPU or GPU detection\n","# Detect hardware, return appropriate distribution strategy\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print(f'Running on TPU {tpu.master()}')\n","except ValueError:\n","    tpu = None\n","    print ('tpu',tpu)\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","else:\n","    strategy = tf.distribute.get_strategy()\n","\n","AUTO = tf.data.experimental.AUTOTUNE\n","REPLICAS = strategy.num_replicas_in_sync\n","print(f'REPLICAS: {REPLICAS}')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Running on TPU grpc://10.13.155.98:8470\n","INFO:tensorflow:Initializing the TPU system: grpc://10.13.155.98:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.13.155.98:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["REPLICAS: 8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NK8TAx9JCaOz","papermill":{"duration":0.035404,"end_time":"2021-01-20T22:57:34.088585","exception":false,"start_time":"2021-01-20T22:57:34.053181","status":"completed"},"tags":[]},"source":["# Model parameters"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:34.155750Z","iopub.status.busy":"2021-01-20T22:57:34.154661Z","iopub.status.idle":"2021-01-20T22:57:34.160980Z","shell.execute_reply":"2021-01-20T22:57:34.160280Z"},"papermill":{"duration":0.040682,"end_time":"2021-01-20T22:57:34.161109","exception":false,"start_time":"2021-01-20T22:57:34.120427","status":"completed"},"tags":[],"id":"hyxJUKF-xGQ2","executionInfo":{"status":"ok","timestamp":1613281221157,"user_tz":-540,"elapsed":322046,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["BATCH_SIZE = 8 * REPLICAS\n","AUG_BATCH = BATCH_SIZE\n","LEARNING_RATE = 1e-5 * REPLICAS"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UmwrOwlYCaOz","papermill":{"duration":0.031304,"end_time":"2021-01-20T22:57:34.223728","exception":false,"start_time":"2021-01-20T22:57:34.192424","status":"completed"},"tags":[]},"source":["# Load data"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:34.290296Z","iopub.status.busy":"2021-01-20T22:57:34.289242Z","iopub.status.idle":"2021-01-20T22:57:35.971447Z","shell.execute_reply":"2021-01-20T22:57:35.971977Z"},"id":"UxM4MGNGCaO0","papermill":{"duration":1.717316,"end_time":"2021-01-20T22:57:35.972129","exception":false,"start_time":"2021-01-20T22:57:34.254813","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1613281223144,"user_tz":-540,"elapsed":324026,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"4177416d-dc68-481e-d906-5dffdc5d2fc8"},"source":["def count_data_items(filenames):\n","    n = [int(re.compile(r'-([0-9]*)\\.').search(filename).group(1)) for filename in filenames]\n","    return np.sum(n)\n","\n","\n","train = pd.read_csv(f'{database_base_path}/train.csv')\n","print(f'Train samples: {len(train)}')\n","\n","FILENAMES_COMP = tf.io.gfile.glob(GCS_PATH + '/*.tfrec')\n","FILENAMES_2019 = tf.io.gfile.glob(GCS_PATH_EXT + '/*.tfrec')\n","\n","FILENAMES_COMP_CBB = tf.io.gfile.glob(GCS_PATH_CLASSES + '/CBB*.tfrec')\n","FILENAMES_COMP_CBSD = tf.io.gfile.glob(GCS_PATH_CLASSES + '/CBSD*.tfrec')\n","FILENAMES_COMP_CGM = tf.io.gfile.glob(GCS_PATH_CLASSES + '/CGM*.tfrec')\n","FILENAMES_COMP_CMD = tf.io.gfile.glob(GCS_PATH_CLASSES + '/CMD*.tfrec')\n","FILENAMES_COMP_Healthy = tf.io.gfile.glob(GCS_PATH_CLASSES + '/Healthy*.tfrec')\n","\n","FILENAMES_2019_CBB = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/CBB*.tfrec')\n","FILENAMES_2019_CBSD = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/CBSD*.tfrec')\n","FILENAMES_2019_CGM = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/CGM*.tfrec')\n","FILENAMES_2019_CMD = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/CMD*.tfrec')\n","FILENAMES_2019_Healthy = tf.io.gfile.glob(GCS_PATH_EXT_CLASSES + '/Healthy*.tfrec')\n","\n","\n","TRAINING_FILENAMES = (FILENAMES_COMP + \n","                      FILENAMES_2019 + \n","                      (2 * FILENAMES_COMP_CBB) + \n","                      (2 * FILENAMES_2019_CBB) + \n","                      (2 * FILENAMES_COMP_CBSD) + \n","                      (2 * FILENAMES_2019_CBSD) + \n","                      (2 * FILENAMES_COMP_CGM) + \n","                      (2 * FILENAMES_2019_CGM) + \n","                      (2 * FILENAMES_COMP_Healthy) + \n","                      (2 * FILENAMES_2019_Healthy))\n","\n","NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n","\n","print(f'GCS: train images: {NUM_TRAINING_IMAGES}')\n","display(train.head())\n","\n","CLASSES = ['Cassava Bacterial Blight', \n","           'Cassava Brown Streak Disease', \n","           'Cassava Green Mottle', \n","           'Cassava Mosaic Disease', \n","           'Healthy']"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable onattempt 1 of 3. Reason: [Errno 115] Operation now in progress\n","WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable onattempt 2 of 3. Reason: [Errno 115] Operation now in progress\n","WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable onattempt 3 of 3. Reason: [Errno 115] Operation now in progress\n","WARNING:google.auth._default:Authentication failed using Compute Engine authentication due to unavailable metadata server.\n"],"name":"stderr"},{"output_type":"stream","text":["Train samples: 21397\n","GCS: train images: 48081\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_id</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000015157.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000201771.jpg</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>100042118.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000723321.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000812911.jpg</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         image_id  label\n","0  1000015157.jpg      0\n","1  1000201771.jpg      3\n","2   100042118.jpg      1\n","3  1000723321.jpg      1\n","4  1000812911.jpg      3"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"BZIhYsg_CaO1","papermill":{"duration":0.032803,"end_time":"2021-01-20T22:57:36.037731","exception":false,"start_time":"2021-01-20T22:57:36.004928","status":"completed"},"tags":[]},"source":["# Augmentation"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:36.106682Z","iopub.status.busy":"2021-01-20T22:57:36.105973Z","iopub.status.idle":"2021-01-20T22:57:36.133193Z","shell.execute_reply":"2021-01-20T22:57:36.133788Z"},"id":"Wwh329L6CaO1","papermill":{"duration":0.063522,"end_time":"2021-01-20T22:57:36.133965","exception":false,"start_time":"2021-01-20T22:57:36.070443","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613281223145,"user_tz":-540,"elapsed":324020,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["def data_augment(image, label):\n","    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    \n","    # Shear\n","    if p_shear > .2:\n","        if p_shear > .6:\n","            image = transform_shear(image, HEIGHT, shear=20.)\n","        else:\n","            image = transform_shear(image, HEIGHT, shear=-20.)\n","            \n","    # Rotation\n","    if p_rotation > .2:\n","        if p_rotation > .6:\n","            image = transform_rotation(image, HEIGHT, rotation=45.)\n","        else:\n","            image = transform_rotation(image, HEIGHT, rotation=-45.)\n","            \n","    # Flips\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_flip_up_down(image)\n","    if p_spatial > .75:\n","        image = tf.image.transpose(image)\n","        \n","    # Rotates\n","    if p_rotate > .75:\n","        image = tf.image.rot90(image, k=3) # rotate 270º\n","    elif p_rotate > .5:\n","        image = tf.image.rot90(image, k=2) # rotate 180º\n","    elif p_rotate > .25:\n","        image = tf.image.rot90(image, k=1) # rotate 90º\n","        \n","    # Pixel-level transforms\n","    if p_pixel_1 >= .4:\n","        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n","    if p_pixel_2 >= .4:\n","        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n","    if p_pixel_3 >= .4:\n","        image = tf.image.random_brightness(image, max_delta=.1)\n","        \n","    # Crops\n","    if p_crop > .6:\n","        if p_crop > .9:\n","            image = tf.image.central_crop(image, central_fraction=.5)\n","        elif p_crop > .8:\n","            image = tf.image.central_crop(image, central_fraction=.6)\n","        elif p_crop > .7:\n","            image = tf.image.central_crop(image, central_fraction=.7)\n","        else:\n","            image = tf.image.central_crop(image, central_fraction=.8)\n","    elif p_crop > .3:\n","        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n","        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n","            \n","    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n","\n","    # if p_cutout > .5:\n","    #     image = data_augment_cutout(image)\n","        \n","    return image, label"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r4Hg1nKgCaO1","papermill":{"duration":0.033215,"end_time":"2021-01-20T22:57:36.199741","exception":false,"start_time":"2021-01-20T22:57:36.166526","status":"completed"},"tags":[]},"source":["## Auxiliary functions"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:36.295009Z","iopub.status.busy":"2021-01-20T22:57:36.289488Z","iopub.status.idle":"2021-01-20T22:57:36.318353Z","shell.execute_reply":"2021-01-20T22:57:36.317633Z"},"id":"-DueNRgfCaO1","papermill":{"duration":0.08607,"end_time":"2021-01-20T22:57:36.318490","exception":false,"start_time":"2021-01-20T22:57:36.232420","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613281223331,"user_tz":-540,"elapsed":324202,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n","def transform_rotation(image, height, rotation):\n","    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n","    # output - image randomly rotated\n","    DIM = height\n","    XDIM = DIM%2 #fix for size 331\n","    \n","    rotation = rotation * tf.random.uniform([1],dtype='float32')\n","    # CONVERT DEGREES TO RADIANS\n","    rotation = math.pi * rotation / 180.\n","    \n","    # ROTATION MATRIX\n","    c1 = tf.math.cos(rotation)\n","    s1 = tf.math.sin(rotation)\n","    one = tf.constant([1],dtype='float32')\n","    zero = tf.constant([0],dtype='float32')\n","    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n","\n","    # LIST DESTINATION PIXEL INDICES\n","    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n","    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n","    z = tf.ones([DIM*DIM],dtype='int32')\n","    idx = tf.stack( [x,y,z] )\n","    \n","    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n","    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n","    idx2 = K.cast(idx2,dtype='int32')\n","    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n","    \n","    # FIND ORIGIN PIXEL VALUES \n","    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n","    d = tf.gather_nd(image, tf.transpose(idx3))\n","        \n","    return tf.reshape(d,[DIM,DIM,3])\n","\n","def transform_shear(image, height, shear):\n","    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n","    # output - image randomly sheared\n","    DIM = height\n","    XDIM = DIM%2 #fix for size 331\n","    \n","    shear = shear * tf.random.uniform([1],dtype='float32')\n","    shear = math.pi * shear / 180.\n","        \n","    # SHEAR MATRIX\n","    one = tf.constant([1],dtype='float32')\n","    zero = tf.constant([0],dtype='float32')\n","    c2 = tf.math.cos(shear)\n","    s2 = tf.math.sin(shear)\n","    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n","\n","    # LIST DESTINATION PIXEL INDICES\n","    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n","    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n","    z = tf.ones([DIM*DIM],dtype='int32')\n","    idx = tf.stack( [x,y,z] )\n","    \n","    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n","    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n","    idx2 = K.cast(idx2,dtype='int32')\n","    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n","    \n","    # FIND ORIGIN PIXEL VALUES \n","    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n","    d = tf.gather_nd(image, tf.transpose(idx3))\n","        \n","    return tf.reshape(d,[DIM,DIM,3])\n","\n","# CutOut\n","def data_augment_cutout(image, min_mask_size=(int(HEIGHT * .1), int(HEIGHT * .1)), \n","                        max_mask_size=(int(HEIGHT * .125), int(HEIGHT * .125))):\n","    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    \n","    if p_cutout > .85: # 10~15 cut outs\n","        n_cutout = tf.random.uniform([], 10, 15, dtype=tf.int32)\n","        image = random_cutout(image, HEIGHT, WIDTH, \n","                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n","    elif p_cutout > .6: # 5~10 cut outs\n","        n_cutout = tf.random.uniform([], 5, 10, dtype=tf.int32)\n","        image = random_cutout(image, HEIGHT, WIDTH, \n","                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n","    elif p_cutout > .25: # 2~5 cut outs\n","        n_cutout = tf.random.uniform([], 2, 5, dtype=tf.int32)\n","        image = random_cutout(image, HEIGHT, WIDTH, \n","                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n","    else: # 1 cut out\n","        image = random_cutout(image, HEIGHT, WIDTH, \n","                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=1)\n","\n","    return image\n","\n","def random_cutout(image, height, width, channels=3, min_mask_size=(10, 10), max_mask_size=(80, 80), k=1):\n","    assert height > min_mask_size[0]\n","    assert width > min_mask_size[1]\n","    assert height > max_mask_size[0]\n","    assert width > max_mask_size[1]\n","\n","    for i in range(k):\n","      mask_height = tf.random.uniform(shape=[], minval=min_mask_size[0], maxval=max_mask_size[0], dtype=tf.int32)\n","      mask_width = tf.random.uniform(shape=[], minval=min_mask_size[1], maxval=max_mask_size[1], dtype=tf.int32)\n","\n","      pad_h = height - mask_height\n","      pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n","      pad_bottom = pad_h - pad_top\n","\n","      pad_w = width - mask_width\n","      pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n","      pad_right = pad_w - pad_left\n","\n","      cutout_area = tf.zeros(shape=[mask_height, mask_width, channels], dtype=tf.uint8)\n","\n","      cutout_mask = tf.pad([cutout_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n","      cutout_mask = tf.squeeze(cutout_mask, axis=0)\n","      image = tf.multiply(tf.cast(image, tf.float32), tf.cast(cutout_mask, tf.float32))\n","\n","    return image"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"hyi3J0MXvJBz","executionInfo":{"status":"ok","timestamp":1613281223332,"user_tz":-540,"elapsed":324199,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["def cutmix(image, label, PROBABILITY = 1.0):\r\n","    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\r\n","    # output - a batch of images with cutmix applied\r\n","    DIM = IMAGE_SIZE[0]\r\n","    CLASSES = N_CLASSES\r\n","    \r\n","    imgs = []; labs = []\r\n","    for j in range(AUG_BATCH):\r\n","        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\r\n","        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\r\n","        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\r\n","        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\r\n","        # CHOOSE RANDOM LOCATION\r\n","        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\r\n","        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\r\n","        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\r\n","        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\r\n","        ya = tf.math.maximum(0,y-WIDTH//2)\r\n","        yb = tf.math.minimum(DIM,y+WIDTH//2)\r\n","        xa = tf.math.maximum(0,x-WIDTH//2)\r\n","        xb = tf.math.minimum(DIM,x+WIDTH//2)\r\n","        # MAKE CUTMIX IMAGE\r\n","        one = image[j,ya:yb,0:xa,:]\r\n","        two = image[k,ya:yb,xa:xb,:]\r\n","        three = image[j,ya:yb,xb:DIM,:]\r\n","        middle = tf.concat([one,two,three],axis=1)\r\n","        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\r\n","        imgs.append(img)\r\n","        # MAKE CUTMIX LABEL\r\n","        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\r\n","        if len(label.shape)==1:\r\n","            lab1 = tf.one_hot(label[j],CLASSES)\r\n","            lab2 = tf.one_hot(label[k],CLASSES)\r\n","        else:\r\n","            lab1 = label[j,]\r\n","            lab2 = label[k,]\r\n","        labs.append((1-a)*lab1 + a*lab2)\r\n","            \r\n","    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\r\n","    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\r\n","    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\r\n","    return image2,label2"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"VD277mUEvLBE","executionInfo":{"status":"ok","timestamp":1613281223332,"user_tz":-540,"elapsed":324195,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["def mixup(image, label, PROBABILITY = 1.0):\r\n","    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\r\n","    # output - a batch of images with mixup applied\r\n","    DIM = IMAGE_SIZE[0]\r\n","    CLASSES = N_CLASSES\r\n","    \r\n","    imgs = []; labs = []\r\n","    for j in range(AUG_BATCH):\r\n","        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\r\n","        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\r\n","        # CHOOSE RANDOM\r\n","        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\r\n","        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\r\n","        # MAKE MIXUP IMAGE\r\n","        img1 = image[j,]\r\n","        img2 = image[k,]\r\n","        imgs.append((1-a)*img1 + a*img2)\r\n","        # MAKE CUTMIX LABEL\r\n","        if len(label.shape)==1:\r\n","            lab1 = tf.one_hot(label[j],CLASSES)\r\n","            lab2 = tf.one_hot(label[k],CLASSES)\r\n","        else:\r\n","            lab1 = label[j,]\r\n","            lab2 = label[k,]\r\n","        labs.append((1-a)*lab1 + a*lab2)\r\n","            \r\n","    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\r\n","    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\r\n","    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\r\n","    return image2,label2"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"AdQEC_iKvR3z","executionInfo":{"status":"ok","timestamp":1613281223691,"user_tz":-540,"elapsed":324550,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["def transform(image,label):\r\n","    # THIS FUNCTION APPLIES BOTH CUTMIX AND MIXUP\r\n","    DIM = IMAGE_SIZE[0]\r\n","    CLASSES = N_CLASSES\r\n","    SWITCH = 0.5\r\n","    CUTMIX_PROB = 0.666\r\n","    MIXUP_PROB = 0.666\r\n","    # FOR SWITCH PERCENT OF TIME WE DO CUTMIX AND (1-SWITCH) WE DO MIXUP\r\n","    image2, label2 = cutmix(image, label, CUTMIX_PROB)\r\n","    image3, label3 = mixup(image, label, MIXUP_PROB)\r\n","    imgs = []; labs = []\r\n","    for j in range(AUG_BATCH):\r\n","        P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\r\n","        imgs.append(P*image2[j,]+(1-P)*image3[j,])\r\n","        labs.append(P*label2[j,]+(1-P)*label3[j,])\r\n","    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\r\n","    image4 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\r\n","    label4 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\r\n","    return image4,label4"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:36.388974Z","iopub.status.busy":"2021-01-20T22:57:36.388107Z","iopub.status.idle":"2021-01-20T22:57:36.415254Z","shell.execute_reply":"2021-01-20T22:57:36.415771Z"},"id":"CPcg0bWECaO1","papermill":{"duration":0.064439,"end_time":"2021-01-20T22:57:36.415960","exception":false,"start_time":"2021-01-20T22:57:36.351521","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613281223691,"user_tz":-540,"elapsed":324546,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["# Datasets utility functions\n","def decode_image(image_data):\n","    \"\"\"\n","        Decode a JPEG-encoded image to a uint8 tensor.\n","    \"\"\"\n","    image = tf.image.decode_jpeg(image_data, channels=3)\n","    return image\n","\n","def scale_image(image, label):\n","    \"\"\"\n","        Cast tensor to float and normalizes (range between 0 and 1).\n","    \"\"\"\n","    image = tf.cast(image, tf.float32)\n","    image /= 255.0\n","    return image, label\n","\n","def prepare_image(image, label):\n","    \"\"\"\n","        Resize and reshape images to the expected size.\n","    \"\"\"\n","    image = tf.image.resize(image, [HEIGHT_RS, WIDTH_RS])\n","    image = tf.reshape(image, [HEIGHT_RS, WIDTH_RS, 3])\n","    return image, label\n","\n","def read_tfrecord(example, labeled=True):\n","    \"\"\"\n","        1. Parse data based on the 'TFREC_FORMAT' map.\n","        2. Decode image.\n","        3. If 'labeled' returns (image, label) if not (image, name).\n","    \"\"\"\n","    if labeled:\n","        TFREC_FORMAT = {\n","            'image': tf.io.FixedLenFeature([], tf.string), \n","            'target': tf.io.FixedLenFeature([], tf.int64), \n","        }\n","    else:\n","        TFREC_FORMAT = {\n","            'image': tf.io.FixedLenFeature([], tf.string), \n","            'image_name': tf.io.FixedLenFeature([], tf.string), \n","        }\n","    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n","    image = decode_image(example['image'])\n","    if labeled:\n","        label_or_name = tf.cast(example['target'], tf.int32)\n","        # One-Hot Encoding needed to use \"categorical_crossentropy\" loss\n","        label_or_name = tf.one_hot(tf.cast(label_or_name, tf.int32), N_CLASSES)\n","    else:\n","        label_or_name = example['image_name']\n","    return image, label_or_name\n","\n","def get_dataset(FILENAMES, labeled=True, ordered=False, repeated=False, \n","                cached=False, augment=False):\n","    \"\"\"\n","        Return a Tensorflow dataset ready for training or inference.\n","    \"\"\"\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False\n","        dataset = tf.data.Dataset.list_files(FILENAMES)\n","        dataset = dataset.interleave(tf.data.TFRecordDataset, num_parallel_calls=AUTO)\n","    else:\n","        dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads=AUTO)\n","        \n","    dataset = dataset.with_options(ignore_order)\n","    \n","    dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled), num_parallel_calls=AUTO)\n","    \n","    if augment:\n","        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n","\n","    if repeated:\n","        dataset = dataset.repeat()\n","        \n","    dataset = dataset.batch(AUG_BATCH)\n","    if augment: \n","        dataset = dataset.map(transform, num_parallel_calls=AUTO) # note we put AFTER batching\n","    dataset = dataset.unbatch()\n","        \n","    dataset = dataset.map(scale_image, num_parallel_calls=AUTO)\n","    dataset = dataset.map(prepare_image, num_parallel_calls=AUTO)\n","    \n","    if not ordered:\n","        dataset = dataset.shuffle(2048)\n","    # if repeated:\n","    #     dataset = dataset.repeat()\n","        \n","    dataset = dataset.batch(BATCH_SIZE)\n","    \n","    if cached:\n","        dataset = dataset.cache()\n","    dataset = dataset.prefetch(AUTO)\n","\n","    return dataset\n","\n","def unfreeze_model(model):\n","    # Unfreeze layers while leaving BatchNorm layers frozen\n","    for layer in model.layers:\n","        if not isinstance(layer, L.BatchNormalization):\n","            layer.trainable = True\n","        else:\n","            layer.trainable = False\n","                \n","def unfreeze_block(model, block_name=None, n_top=3):\n","    # Unfreeze layers while leaving BatchNorm layers frozen\n","    for layer in model.layers[:-n_top]:\n","        if isinstance(layer, L.BatchNormalization):\n","            layer.trainable = False\n","        else:\n","            if block_name and (block_name in layer.name):\n","                layer.trainable = True"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:36.487403Z","iopub.status.busy":"2021-01-20T22:57:36.486600Z","iopub.status.idle":"2021-01-20T22:57:36.530480Z","shell.execute_reply":"2021-01-20T22:57:36.531039Z"},"id":"gHAxNOInCaO2","papermill":{"duration":0.081913,"end_time":"2021-01-20T22:57:36.531213","exception":false,"start_time":"2021-01-20T22:57:36.449300","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613281223882,"user_tz":-540,"elapsed":324732,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["# Visualization utility functions\n","np.set_printoptions(threshold=15, linewidth=80)\n","\n","def batch_to_numpy_images_and_labels(data):\n","    images, labels = data\n","    numpy_images = images.numpy()\n","    numpy_labels = labels.numpy()\n","    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n","        numpy_labels = [None for _ in enumerate(numpy_images)]\n","    # If no labels, only image IDs, return None for labels (this is the case for test data)\n","    return numpy_images, numpy_labels\n","\n","def title_from_label_and_target(label, correct_label):\n","    if correct_label is None:\n","        return CLASSES[label], True\n","    correct = (label == correct_label)\n","    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n","                                CLASSES[correct_label] if not correct else ''), correct\n","\n","def display_one_flower(image, title, subplot, red=False, titlesize=16):\n","    plt.subplot(*subplot)\n","    plt.axis('off')\n","    plt.imshow(image)\n","    if len(title) > 0:\n","        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', \n","                  fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n","    return (subplot[0], subplot[1], subplot[2]+1)\n","\n","def display_batch_of_images(databatch, predictions=None):\n","    \"\"\"This will work with:\n","    display_batch_of_images(images)\n","    display_batch_of_images(images, predictions)\n","    display_batch_of_images((images, labels))\n","    display_batch_of_images((images, labels), predictions)\n","    \"\"\"\n","    # data\n","    images, labels = batch_to_numpy_images_and_labels(databatch)\n","    labels = np.argmax(labels, axis=-1)\n","    if labels is None:\n","        labels = [None for _ in enumerate(images)]\n","        \n","    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n","    rows = int(math.sqrt(len(images)))\n","    cols = len(images)//rows\n","        \n","    # size and spacing\n","    FIGSIZE = 13.0\n","    SPACING = 0.1\n","    subplot=(rows,cols,1)\n","    if rows < cols:\n","        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n","    else:\n","        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n","    \n","    # display\n","    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n","        title = '' if label is None else CLASSES[label]\n","        correct = True\n","        if predictions is not None:\n","            title, correct = title_from_label_and_target(predictions[i], label)\n","        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n","        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n","    \n","    #layout\n","    plt.tight_layout()\n","    if label is None and predictions is None:\n","        plt.subplots_adjust(wspace=0, hspace=0)\n","    else:\n","        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n","    plt.show()\n","    \n","# Visualize model predictions\n","def dataset_to_numpy_util(dataset, N):\n","    dataset = dataset.unbatch().batch(N)\n","    for images, labels in dataset:\n","        numpy_images = images.numpy()\n","        numpy_labels = labels.numpy()\n","        break;  \n","    return numpy_images, numpy_labels\n","\n","def title_from_label_and_target(label, correct_label):\n","    label = np.argmax(label, axis=-1)\n","    correct = (label == correct_label)\n","    return \"{} [{}{}{}]\".format(label, str(correct), ', shoud be ' if not correct else '',\n","                                correct_label if not correct else ''), correct\n","\n","def display_one_flower_eval(image, title, subplot, red=False):\n","    plt.subplot(subplot)\n","    plt.axis('off')\n","    plt.imshow(image)\n","    plt.title(title, fontsize=14, color='red' if red else 'black')\n","    return subplot+1\n","\n","def display_9_images_with_predictions(images, predictions, labels):\n","    subplot=331\n","    plt.figure(figsize=(13,13))\n","    for i, image in enumerate(images):\n","        title, correct = title_from_label_and_target(predictions[i], labels[i])\n","        subplot = display_one_flower_eval(image, title, subplot, not correct)\n","        if i >= 8:\n","            break;\n","              \n","    plt.tight_layout()\n","    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n","    plt.show()\n","\n","\n","# Model evaluation\n","def plot_metrics(history):\n","    fig, axes = plt.subplots(2, 1, sharex='col', figsize=(20, 8))\n","    axes = axes.flatten()\n","    \n","    axes[0].plot(history['loss'], label='Train loss')\n","    axes[0].plot(history['val_loss'], label='Validation loss')\n","    axes[0].legend(loc='best', fontsize=16)\n","    axes[0].set_title('Loss')\n","    axes[0].axvline(np.argmin(history['loss']), linestyle='dashed')\n","    axes[0].axvline(np.argmin(history['val_loss']), linestyle='dashed', color='orange')\n","    \n","    axes[1].plot(history['accuracy'], label='Train accuracy')\n","    axes[1].plot(history['val_accuracy'], label='Validation accuracy')\n","    axes[1].legend(loc='best', fontsize=16)\n","    axes[1].set_title('Accuracy')\n","    axes[1].axvline(np.argmax(history['accuracy']), linestyle='dashed')\n","    axes[1].axvline(np.argmax(history['val_accuracy']), linestyle='dashed', color='orange')\n","\n","    plt.xlabel('Epochs', fontsize=16)\n","    sns.despine()\n","    plt.show()"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oCtCB3WdCaO2","papermill":{"duration":0.033127,"end_time":"2021-01-20T22:57:36.597612","exception":false,"start_time":"2021-01-20T22:57:36.564485","status":"completed"},"tags":[]},"source":["# Training data samples (with augmentation)"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T22:57:36.667226Z","iopub.status.busy":"2021-01-20T22:57:36.666549Z","iopub.status.idle":"2021-01-20T22:57:52.204000Z","shell.execute_reply":"2021-01-20T22:57:52.204539Z"},"id":"p8IMzXLRCaO2","papermill":{"duration":15.574028,"end_time":"2021-01-20T22:57:52.204708","exception":false,"start_time":"2021-01-20T22:57:36.630680","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1VdvuMCAFbmvm01RUKFzhheZrdw0budmU"},"executionInfo":{"status":"ok","timestamp":1613281253151,"user_tz":-540,"elapsed":353992,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"372d7f85-67ed-43db-8564-fdd4a00f3166"},"source":["train_dataset = get_dataset(FILENAMES_COMP, ordered=True, augment=True)\n","train_iter = iter(train_dataset.unbatch().batch(20))\n","\n","display_batch_of_images(next(train_iter))\n","display_batch_of_images(next(train_iter))"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"HvXRzhofCaO5","papermill":{"duration":0.112509,"end_time":"2021-01-20T23:02:43.580615","exception":false,"start_time":"2021-01-20T23:02:43.468106","status":"completed"},"tags":[]},"source":["### Learning rate schedule\n","\n","We are going to use a `cosine learning rate schedule with a warm-up phase`, this may be a good idea since we are using a pre-trained model, the warm-up phase will be useful to avoid the pre-trained weights degradation resulting in catastrophic forgetting, during the schedule the learning rate will slowly decrease to very low values, this helps the model to land on more stable weights."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:02:43.808753Z","iopub.status.busy":"2021-01-20T23:02:43.807680Z","iopub.status.idle":"2021-01-20T23:02:47.940826Z","shell.execute_reply":"2021-01-20T23:02:47.939748Z"},"id":"I9cuJCl1CaO5","papermill":{"duration":4.248898,"end_time":"2021-01-20T23:02:47.940988","exception":false,"start_time":"2021-01-20T23:02:43.692090","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":422},"executionInfo":{"status":"ok","timestamp":1613281333912,"user_tz":-540,"elapsed":434746,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}},"outputId":"dd16f7fc-f342-468f-b113-5b19bcae0e1c"},"source":["lr_start = 1e-8\n","lr_min = 1e-8\n","lr_max = LEARNING_RATE\n","num_cycles = 1.\n","warmup_epochs = 1\n","hold_max_epochs = 0\n","total_epochs = EPOCHS\n","warmup_steps = warmup_epochs * (NUM_TRAINING_IMAGES//BATCH_SIZE)\n","total_steps = total_epochs * (NUM_TRAINING_IMAGES//BATCH_SIZE)\n","\n","@tf.function\n","def lrfn(step):\n","    if step < warmup_steps:\n","        lr = (lr_max - lr_start) / warmup_steps * step + lr_start\n","    else:\n","        progress = (step - warmup_steps) / (total_steps - warmup_steps)\n","        lr = lr_max * (0.5 * (1.0 + tf.math.cos(np.pi * ((num_cycles * progress) % 1.0))))\n","        if lr_min is not None:\n","            lr = tf.math.maximum(lr_min, float(lr))\n","\n","    return lr\n","\n","\n","# rng = [i for i in range(total_epochs)]\n","rng = [i for i in range(total_steps)]\n","y = [lrfn(tf.cast(x, tf.float32)) for x in rng]\n","\n","sns.set(style='whitegrid')\n","fig, ax = plt.subplots(figsize=(20, 6))\n","plt.plot(rng, y)\n","\n","print(f'{total_steps} total steps and {NUM_TRAINING_IMAGES//BATCH_SIZE} steps per epoch')\n","print(f'Learning rate schedule: {y[0]:.3g} to {max(y):.3g} to {y[-1]:.3g}')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["15020 total steps and 751 steps per epoch\n","Learning rate schedule: 1e-08 to 8e-05 to 1e-08\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1440x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"OMIrA5jxCaO5","papermill":{"duration":0.112158,"end_time":"2021-01-20T23:02:48.166235","exception":false,"start_time":"2021-01-20T23:02:48.054077","status":"completed"},"tags":[]},"source":["# Model"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:02:48.402810Z","iopub.status.busy":"2021-01-20T23:02:48.402111Z","iopub.status.idle":"2021-01-20T23:02:48.406439Z","shell.execute_reply":"2021-01-20T23:02:48.405740Z"},"id":"pRksD6K6CaO5","papermill":{"duration":0.126526,"end_time":"2021-01-20T23:02:48.406566","exception":false,"start_time":"2021-01-20T23:02:48.280040","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613281333912,"user_tz":-540,"elapsed":434739,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["def model_fn(input_shape, N_CLASSES):\n","    inputs = L.Input(shape=input_shape, name='input_image')\n","    base_model = efn.EfficientNetB7(input_tensor=inputs, \n","                                    include_top=False, \n","                                    weights='noisy-student', \n","                                    pooling='avg')\n","    base_model.trainable = False\n","    x = L.Dropout(.25)(base_model.output)\n","    output = L.Dense(N_CLASSES, activation='softmax', name='output')(x)\n","    model = Model(inputs=inputs, outputs=output)\n","\n","    return model"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:02:48.640007Z","iopub.status.busy":"2021-01-20T23:02:48.638735Z","iopub.status.idle":"2021-01-20T23:02:48.642985Z","shell.execute_reply":"2021-01-20T23:02:48.643690Z"},"id":"4zl0qy-pcR-A","papermill":{"duration":0.122772,"end_time":"2021-01-20T23:02:48.643846","exception":false,"start_time":"2021-01-20T23:02:48.521074","status":"completed"},"tags":[],"executionInfo":{"status":"ok","timestamp":1613281333913,"user_tz":-540,"elapsed":434736,"user":{"displayName":"鎌田康太郎","photoUrl":"https://lh3.googleusercontent.com/-kcpEta3hFnI/AAAAAAAAAAI/AAAAAAAAAMU/efKY0LsQQVA/s64/photo.jpg","userId":"14776559597549076807"}}},"source":["#help(strategy)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hMc0tk0VCaO5","papermill":{"duration":0.114465,"end_time":"2021-01-20T23:02:48.871581","exception":false,"start_time":"2021-01-20T23:02:48.757116","status":"completed"},"tags":[]},"source":["# Training"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:02:49.104256Z","iopub.status.busy":"2021-01-20T23:02:49.103030Z","iopub.status.idle":"2021-01-20T23:41:32.330134Z","shell.execute_reply":"2021-01-20T23:41:32.329366Z"},"id":"8HrFGFRNCaO5","papermill":{"duration":2323.344808,"end_time":"2021-01-20T23:41:32.330270","exception":false,"start_time":"2021-01-20T23:02:48.985462","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f6af2417-7dc2-4c88-faa5-f5a67d26a3bd"},"source":["skf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n","oof_pred = []; oof_labels = []; history_list = []\n","\n","for fold,(idxT, idxV) in enumerate(skf.split(np.arange(50))):\n","    if fold >= FOLDS_USED:\n","        break\n","    if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n","    K.clear_session()\n","    print(f'\\nFOLD: {fold+1}')\n","    print(f'TRAIN: {idxT} VALID: {idxV}')\n","\n","    # Create train and validation sets\n","    FILENAMES_COMP = tf.io.gfile.glob([GCS_PATH + '/Id_train%.2i*.tfrec' % x for x in idxT])\n","    FILENAMES_2019 = tf.io.gfile.glob([GCS_PATH_EXT + '/Id_train%.2i*.tfrec' % x for x in idxT])\n","\n","    FILENAMES_COMP_CBB = tf.io.gfile.glob([GCS_PATH_CLASSES + '/CBB%.2i*.tfrec' % x for x in idxT])\n","    FILENAMES_COMP_CBSD = tf.io.gfile.glob([GCS_PATH_CLASSES + '/CBSD%.2i*.tfrec' % x for x in idxT])\n","    FILENAMES_COMP_CGM = tf.io.gfile.glob([GCS_PATH_CLASSES + '/CGM%.2i*.tfrec' % x for x in idxT])\n","    FILENAMES_COMP_Healthy = tf.io.gfile.glob([GCS_PATH_CLASSES + '/Healthy%.2i*.tfrec' % x for x in idxT])\n","    \n","    FILENAMES_2019_CBB = tf.io.gfile.glob([GCS_PATH_EXT_CLASSES + '/CBB%.2i*.tfrec' % x for x in idxT])\n","    FILENAMES_2019_CBSD = tf.io.gfile.glob([GCS_PATH_EXT_CLASSES + '/CBSD%.2i*.tfrec' % x for x in idxT])\n","    FILENAMES_2019_CGM = tf.io.gfile.glob([GCS_PATH_EXT_CLASSES + '/CGM%.2i*.tfrec' % x for x in idxT])\n","    FILENAMES_2019_Healthy = tf.io.gfile.glob([GCS_PATH_EXT_CLASSES + '/Healthy%.2i*.tfrec' % x for x in idxT])\n","\n","    TRAIN_FILENAMES = (FILENAMES_COMP + \n","                       FILENAMES_2019 + \n","                       (2 * FILENAMES_COMP_CBB) + \n","                       (2 * FILENAMES_2019_CBB) + \n","                       (2 * FILENAMES_COMP_CBSD) + \n","                       (2 * FILENAMES_2019_CBSD) + \n","                       (2 * FILENAMES_COMP_CGM) + \n","                       (2 * FILENAMES_2019_CGM) + \n","                       (2 * FILENAMES_COMP_Healthy) + \n","                       (2 * FILENAMES_2019_Healthy))\n","    \n","    VALID_FILENAMES = tf.io.gfile.glob([GCS_PATH + '/Id_train%.2i*.tfrec' % x for x in idxV])\n","    np.random.shuffle(TRAIN_FILENAMES)\n","    \n","    ct_train = count_data_items(TRAIN_FILENAMES)\n","    ct_valid = count_data_items(VALID_FILENAMES)\n","    \n","    step_size = (ct_train // BATCH_SIZE)\n","    valid_step_size = (ct_valid // BATCH_SIZE)\n","    total_steps=(total_epochs * step_size)\n","    warmup_steps=(warmup_epochs * step_size)\n","    \n","    \n","    # Build TF datasets\n","    train_ds = strategy.experimental_distribute_dataset(get_dataset(TRAIN_FILENAMES, repeated=True, augment=True))\n","    valid_ds = strategy.experimental_distribute_dataset(get_dataset(VALID_FILENAMES, ordered=True, repeated=True, cached=True))\n","    train_data_iter = iter(train_ds)\n","    valid_data_iter = iter(valid_ds)\n","    \n","    \n","    # Step functions\n","    @tf.function\n","    def train_step(data_iter):\n","        def train_step_fn(x, y):\n","            with tf.GradientTape() as tape:\n","                probabilities = model(x, training=True)\n","                loss = loss_fn(y, probabilities, label_smoothing=.3)\n","            gradients = tape.gradient(loss, model.trainable_variables)\n","            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","            # update metrics\n","            train_accuracy.update_state(y, probabilities)\n","            train_loss.update_state(loss)\n","        for _ in tf.range(step_size):\n","            if COLAB:\n","                #print(COLAB)\n","                strategy.experimental_run_v2(train_step_fn, next(data_iter))\n","            else:\n","                strategy.experimental_run_v2(train_step_fn, next(data_iter))\n","\n","    @tf.function\n","    def valid_step(data_iter):\n","        def valid_step_fn(x, y):\n","            probabilities = model(x, training=False)\n","            loss = loss_fn(y, probabilities)\n","            # update metrics\n","            valid_accuracy.update_state(y, probabilities)\n","            valid_loss.update_state(loss)\n","        for _ in tf.range(valid_step_size):\n","            if COLAB:\n","                strategy.experimental_run_v2(valid_step_fn, next(data_iter))\n","            else:\n","                strategy.experimental_run_v2(valid_step_fn, next(data_iter))\n","    \n","    \n","    # Model\n","    model_path = models_path+f'model_{fold}.h5'\n","    with strategy.scope():\n","        model = model_fn((None, None, CHANNELS), N_CLASSES)\n","        unfreeze_model(model) # unfreeze all layers except \"batch normalization\"\n","        \n","        optimizer = optimizers.Adam(learning_rate=lambda: lrfn(tf.cast(optimizer.iterations, tf.float32)))\n","        loss_fn = losses.categorical_crossentropy\n","\n","        train_accuracy = metrics.CategoricalAccuracy()\n","        valid_accuracy = metrics.CategoricalAccuracy()\n","        train_loss = metrics.Sum()\n","        valid_loss = metrics.Sum()\n","    \n","    \n","    # Setup training loop\n","    step = 0\n","    epoch_steps = 0\n","    patience_cnt = 0\n","    best_val = 0\n","    history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}\n","\n","    ### Train model\n","    for epoch in range(EPOCHS):\n","        epoch_start_time = time.time()\n","\n","        # Run training step\n","        train_step(train_data_iter)\n","        epoch_steps += step_size\n","        step += step_size\n","            \n","\n","        # Validation run at the end of each epoch\n","        if (step // step_size) > epoch:\n","            # Validation run\n","            valid_epoch_steps = 0\n","            valid_step(valid_data_iter)\n","            valid_epoch_steps += valid_step_size\n","\n","            # Compute metrics\n","            history['accuracy'].append(train_accuracy.result().numpy())\n","            history['loss'].append(train_loss.result().numpy() / (BATCH_SIZE * epoch_steps))\n","            history['val_accuracy'].append(valid_accuracy.result().numpy())\n","            history['val_loss'].append(valid_loss.result().numpy() / (BATCH_SIZE * valid_epoch_steps))\n","\n","            # Report metrics\n","            epoch_time = time.time() - epoch_start_time\n","            print(f'\\nEPOCH {epoch+1}/{EPOCHS}')\n","            print(f'time: {epoch_time:0.1f}s',\n","                  f\"loss: {history['loss'][-1]:0.4f}\",\n","                  f\"accuracy: {history['accuracy'][-1]:0.4f}\",\n","                  f\"val_loss: {history['val_loss'][-1]:0.4f}\",\n","                  f\"val_accuracy: {history['val_accuracy'][-1]:0.4f}\",\n","                  f'lr: {lrfn(tf.cast(optimizer.iterations, tf.int32).numpy()):0.4g}')\n","\n","            # Early stopping monitor\n","            if history['val_accuracy'][-1] >= best_val:\n","                best_val = history['val_accuracy'][-1]\n","                model.save_weights(model_path)\n","                print(f'Saved model weights at \"{model_path}\"')\n","                patience_cnt = 1\n","            else:\n","                patience_cnt += 1\n","            # if patience_cnt > ES_PATIENCE:\n","            #     print(f'Epoch {epoch:05d}: early stopping')\n","            #     break\n","\n","                \n","            # Set up next epoch\n","            epoch = step // step_size\n","            epoch_steps = 0\n","            train_accuracy.reset_states()\n","            train_loss.reset_states()\n","            valid_accuracy.reset_states()\n","            valid_loss.reset_states()\n","    \n","    \n","    ### RESULTS\n","    print(f\"#### FOLD {fold+1} OOF Accuracy = {np.max(history['val_accuracy']):.3f}\")\n","    \n","    history_list.append(history)\n","    # Load best model weights\n","    model.load_weights(model_path)\n","\n","    # OOF predictions\n","    ds_valid = get_dataset(VALID_FILENAMES, ordered=True)\n","    oof_labels.append([target.numpy() for img, target in iter(ds_valid.unbatch())])\n","    x_oof = ds_valid.map(lambda image, target: image)\n","    oof_pred.append(np.argmax(model.predict(x_oof), axis=-1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.13.155.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.13.155.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.13.155.98:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.13.155.98:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","FOLD: 1\n","TRAIN: [ 0  1  3 ... 47 48 49] VALID: [ 2  4 10 11 22 27 28 31 38 41]\n","Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b7_noisy-student_notop.h5\n","258072576/258068648 [==============================] - 2s 0us/step\n","WARNING:tensorflow:From <ipython-input-21-d506d5d257e7>:71: StrategyBase.experimental_run_v2 (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","renamed to `run`\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-21-d506d5d257e7>:71: StrategyBase.experimental_run_v2 (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","renamed to `run`\n"],"name":"stderr"},{"output_type":"stream","text":["\n","EPOCH 1/20\n","time: 498.5s loss: 1.3831 accuracy: 0.5737 val_loss: 0.7319 val_accuracy: 0.8494 lr: 8e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 2/20\n","time: 248.2s loss: 1.2572 accuracy: 0.7249 val_loss: 0.6849 val_accuracy: 0.8681 lr: 7.945e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 3/20\n","time: 248.1s loss: 1.2326 accuracy: 0.7470 val_loss: 0.6597 val_accuracy: 0.8868 lr: 7.783e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 4/20\n","WARNING:tensorflow:5 out of the last 389 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 389 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.2s loss: 1.2226 accuracy: 0.7571 val_loss: 0.6452 val_accuracy: 0.8764 lr: 7.518e-05\n","\n","EPOCH 5/20\n","WARNING:tensorflow:6 out of the last 390 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 390 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.2s loss: 1.2115 accuracy: 0.7719 val_loss: 0.6069 val_accuracy: 0.8845 lr: 7.157e-05\n","\n","EPOCH 6/20\n","WARNING:tensorflow:7 out of the last 391 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 391 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.6s loss: 1.2053 accuracy: 0.7757 val_loss: 0.6754 val_accuracy: 0.8854 lr: 6.709e-05\n","\n","EPOCH 7/20\n","WARNING:tensorflow:8 out of the last 392 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 392 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.2s loss: 1.1958 accuracy: 0.7870 val_loss: 0.6571 val_accuracy: 0.8793 lr: 6.188e-05\n","\n","EPOCH 8/20\n","WARNING:tensorflow:9 out of the last 393 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 393 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.1s loss: 1.1874 accuracy: 0.7948 val_loss: 0.5898 val_accuracy: 0.8904 lr: 5.607e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 9/20\n","WARNING:tensorflow:10 out of the last 394 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 394 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.4s loss: 1.1840 accuracy: 0.7970 val_loss: 0.5926 val_accuracy: 0.8913 lr: 4.982e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 10/20\n","WARNING:tensorflow:11 out of the last 395 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 395 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.5s loss: 1.1775 accuracy: 0.8040 val_loss: 0.5935 val_accuracy: 0.8930 lr: 4.33e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 11/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.4s loss: 1.1758 accuracy: 0.8077 val_loss: 0.6159 val_accuracy: 0.8916 lr: 3.67e-05\n","\n","EPOCH 12/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.7s loss: 1.1685 accuracy: 0.8141 val_loss: 0.5952 val_accuracy: 0.8918 lr: 3.018e-05\n","\n","EPOCH 13/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.7s loss: 1.1623 accuracy: 0.8182 val_loss: 0.6094 val_accuracy: 0.8918 lr: 2.393e-05\n","\n","EPOCH 14/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.4s loss: 1.1588 accuracy: 0.8199 val_loss: 0.6073 val_accuracy: 0.8902 lr: 1.812e-05\n","\n","EPOCH 15/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.5s loss: 1.1545 accuracy: 0.8269 val_loss: 0.6139 val_accuracy: 0.8909 lr: 1.291e-05\n","\n","EPOCH 16/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.4s loss: 1.1552 accuracy: 0.8285 val_loss: 0.6121 val_accuracy: 0.8928 lr: 8.434e-06\n","\n","EPOCH 17/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 249.3s loss: 1.1511 accuracy: 0.8345 val_loss: 0.5922 val_accuracy: 0.8937 lr: 4.821e-06\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 18/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.8s loss: 1.1523 accuracy: 0.8306 val_loss: 0.5879 val_accuracy: 0.8923 lr: 2.167e-06\n","\n","EPOCH 19/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.4s loss: 1.1494 accuracy: 0.8324 val_loss: 0.5854 val_accuracy: 0.8946 lr: 5.455e-07\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_0.h5\"\n","\n","EPOCH 20/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.7s loss: 1.1503 accuracy: 0.8332 val_loss: 0.6049 val_accuracy: 0.8918 lr: 8e-05\n","#### FOLD 1 OOF Accuracy = 0.895\n","WARNING:tensorflow:TPU system grpc://10.13.155.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.13.155.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.13.155.98:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.13.155.98:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","FOLD: 2\n","TRAIN: [ 0  1  2 ... 46 47 49] VALID: [ 7 14 18 26 29 33 34 35 45 48]\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","EPOCH 1/20\n","time: 499.1s loss: 1.3842 accuracy: 0.5716 val_loss: 0.7533 val_accuracy: 0.8274 lr: 8e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_1.h5\"\n","\n","EPOCH 2/20\n","time: 245.7s loss: 1.2524 accuracy: 0.7302 val_loss: 0.6412 val_accuracy: 0.8899 lr: 7.945e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_1.h5\"\n","\n","EPOCH 3/20\n","time: 246.3s loss: 1.2323 accuracy: 0.7504 val_loss: 0.6141 val_accuracy: 0.8757 lr: 7.783e-05\n","\n","EPOCH 4/20\n","WARNING:tensorflow:5 out of the last 389 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 389 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 246.5s loss: 1.2223 accuracy: 0.7592 val_loss: 0.7251 val_accuracy: 0.8580 lr: 7.518e-05\n","\n","EPOCH 5/20\n","WARNING:tensorflow:6 out of the last 390 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 390 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 246.8s loss: 1.2089 accuracy: 0.7729 val_loss: 0.6178 val_accuracy: 0.8883 lr: 7.157e-05\n","\n","EPOCH 6/20\n","WARNING:tensorflow:7 out of the last 391 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 391 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 247.0s loss: 1.2020 accuracy: 0.7768 val_loss: 0.5817 val_accuracy: 0.8871 lr: 6.709e-05\n","\n","EPOCH 7/20\n","WARNING:tensorflow:8 out of the last 392 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 392 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 246.9s loss: 1.1991 accuracy: 0.7798 val_loss: 0.6299 val_accuracy: 0.8738 lr: 6.188e-05\n","\n","EPOCH 8/20\n","WARNING:tensorflow:9 out of the last 393 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 393 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 247.0s loss: 1.1881 accuracy: 0.7929 val_loss: 0.6307 val_accuracy: 0.8795 lr: 5.607e-05\n","\n","EPOCH 9/20\n","WARNING:tensorflow:10 out of the last 394 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 394 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 246.9s loss: 1.1845 accuracy: 0.7975 val_loss: 0.6046 val_accuracy: 0.8847 lr: 4.982e-05\n","\n","EPOCH 10/20\n","WARNING:tensorflow:11 out of the last 395 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 395 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 247.1s loss: 1.1763 accuracy: 0.8026 val_loss: 0.5773 val_accuracy: 0.8920 lr: 4.33e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_1.h5\"\n","\n","EPOCH 11/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 247.1s loss: 1.1727 accuracy: 0.8116 val_loss: 0.6218 val_accuracy: 0.8835 lr: 3.67e-05\n","\n","EPOCH 12/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 247.3s loss: 1.1695 accuracy: 0.8150 val_loss: 0.5945 val_accuracy: 0.8935 lr: 3.018e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_1.h5\"\n","\n","EPOCH 13/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 247.3s loss: 1.1639 accuracy: 0.8199 val_loss: 0.5955 val_accuracy: 0.8866 lr: 2.393e-05\n","\n","EPOCH 14/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 247.4s loss: 1.1628 accuracy: 0.8195 val_loss: 0.5869 val_accuracy: 0.8899 lr: 1.812e-05\n","\n","EPOCH 15/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 247.0s loss: 1.1555 accuracy: 0.8260 val_loss: 0.5941 val_accuracy: 0.8880 lr: 1.291e-05\n","\n","EPOCH 16/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 247.6s loss: 1.1528 accuracy: 0.8303 val_loss: 0.5783 val_accuracy: 0.8951 lr: 8.434e-06\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_1.h5\"\n","\n","EPOCH 17/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 247.5s loss: 1.1552 accuracy: 0.8277 val_loss: 0.5766 val_accuracy: 0.8958 lr: 4.821e-06\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_1.h5\"\n","\n","EPOCH 18/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 247.8s loss: 1.1554 accuracy: 0.8268 val_loss: 0.5707 val_accuracy: 0.8963 lr: 2.167e-06\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_1.h5\"\n","\n","EPOCH 19/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 247.8s loss: 1.1494 accuracy: 0.8342 val_loss: 0.5717 val_accuracy: 0.8963 lr: 5.455e-07\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_1.h5\"\n","\n","EPOCH 20/20\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["time: 248.1s loss: 1.1507 accuracy: 0.8327 val_loss: 0.5826 val_accuracy: 0.8949 lr: 8e-05\n","#### FOLD 2 OOF Accuracy = 0.896\n","WARNING:tensorflow:TPU system grpc://10.13.155.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.13.155.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.13.155.98:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.13.155.98:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","FOLD: 3\n","TRAIN: [ 0  1  2 ... 47 48 49] VALID: [ 8 13 15 16 20 25 30 32 42 43]\n","WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function lrfn at 0x7fb5f7d8d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","EPOCH 1/20\n","time: 497.2s loss: 1.3818 accuracy: 0.5757 val_loss: 0.7253 val_accuracy: 0.8549 lr: 8e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_2.h5\"\n","\n","EPOCH 2/20\n","time: 246.0s loss: 1.2538 accuracy: 0.7287 val_loss: 0.6425 val_accuracy: 0.8724 lr: 7.945e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_2.h5\"\n","\n","EPOCH 3/20\n","time: 246.2s loss: 1.2331 accuracy: 0.7451 val_loss: 0.6075 val_accuracy: 0.8776 lr: 7.783e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_2.h5\"\n","\n","EPOCH 4/20\n","time: 246.4s loss: 1.2171 accuracy: 0.7618 val_loss: 0.6345 val_accuracy: 0.8866 lr: 7.518e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_2.h5\"\n","\n","EPOCH 5/20\n","time: 246.5s loss: 1.2091 accuracy: 0.7709 val_loss: 0.5956 val_accuracy: 0.8871 lr: 7.157e-05\n","Saved model weights at \"/content/drive/MyDrive/Colab Notebooks/Cassava/model/model_2.h5\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NQyHtXnRCaO5","papermill":{"duration":0.130935,"end_time":"2021-01-20T23:41:32.592224","exception":false,"start_time":"2021-01-20T23:41:32.461289","status":"completed"},"tags":[]},"source":["## Model loss graph"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:41:32.862698Z","iopub.status.busy":"2021-01-20T23:41:32.861475Z","iopub.status.idle":"2021-01-20T23:41:35.936240Z","shell.execute_reply":"2021-01-20T23:41:35.935506Z"},"id":"_7pUdch3CaO6","papermill":{"duration":3.212527,"end_time":"2021-01-20T23:41:35.936368","exception":false,"start_time":"2021-01-20T23:41:32.723841","status":"completed"},"tags":[]},"source":["for fold, history in enumerate(history_list):\n","    print(f'\\nFOLD: {fold+1}')\n","    plot_metrics(history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ImheYrtKCaO7","papermill":{"duration":0.140565,"end_time":"2021-01-20T23:41:36.235070","exception":false,"start_time":"2021-01-20T23:41:36.094505","status":"completed"},"tags":[]},"source":["# Model evaluation\n","\n","Now we can evaluate the performance of the model, first, we can evaluate the usual metrics like, `accuracy`, `precision`, `recall`, and `f1-score`, `scikit-learn` provides the perfect function for this `classification_report`.\n","\n","We are evaluating the model on the `OOF` predictions, it stands for `Out Of Fold`, since we are training using `K-Fold` our model will see all the data, and the correct way to evaluate each fold is by looking at the predictions that are not from that fold.\n","\n","## OOF metrics"]},{"cell_type":"markdown","metadata":{"id":"I_QvO8rPCaO7","papermill":{"duration":0.142773,"end_time":"2021-01-20T23:41:36.524904","exception":false,"start_time":"2021-01-20T23:41:36.382131","status":"completed"},"tags":[]},"source":["#### I am still having some problems to get the real model `OOF` scores while using `TPU Pods`, so the results here and the confusion matrix are just placeholders."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:41:36.817847Z","iopub.status.busy":"2021-01-20T23:41:36.816550Z","iopub.status.idle":"2021-01-20T23:41:36.871365Z","shell.execute_reply":"2021-01-20T23:41:36.870279Z"},"id":"q7TfhkICCaO7","papermill":{"duration":0.205034,"end_time":"2021-01-20T23:41:36.871548","exception":false,"start_time":"2021-01-20T23:41:36.666514","status":"completed"},"tags":[]},"source":["y_true = np.concatenate(oof_labels)\n","y_true = np.argmax(y_true, axis=-1)\n","y_pred = np.concatenate(oof_pred)\n","\n","print(classification_report(y_true, y_pred, target_names=CLASSES))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pIAJafCnCaO7","papermill":{"duration":0.1407,"end_time":"2021-01-20T23:41:37.153525","exception":false,"start_time":"2021-01-20T23:41:37.012825","status":"completed"},"tags":[]},"source":["# Confusion matrix\n","\n","Let's also take a look at the confusion matrix, this will give us an idea about what classes the model is mixing or having a hard time."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:41:37.451948Z","iopub.status.busy":"2021-01-20T23:41:37.451220Z","iopub.status.idle":"2021-01-20T23:41:37.902193Z","shell.execute_reply":"2021-01-20T23:41:37.902770Z"},"id":"dw2F8Wk2CaO7","papermill":{"duration":0.608362,"end_time":"2021-01-20T23:41:37.902957","exception":false,"start_time":"2021-01-20T23:41:37.294595","status":"completed"},"tags":[]},"source":["fig, ax = plt.subplots(1, 1, figsize=(20, 12))\n","cfn_matrix = confusion_matrix(y_true, y_pred, labels=range(len(CLASSES)))\n","cfn_matrix = (cfn_matrix.T / cfn_matrix.sum(axis=1)).T\n","df_cm = pd.DataFrame(cfn_matrix, index=CLASSES, columns=CLASSES)\n","ax = sns.heatmap(df_cm, cmap='Blues', annot=True, fmt='.2f', linewidths=.5).set_title('Train', fontsize=30)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AaZVX_ZhCaO7","papermill":{"duration":0.14275,"end_time":"2021-01-20T23:41:38.189478","exception":false,"start_time":"2021-01-20T23:41:38.046728","status":"completed"},"tags":[]},"source":["# Visualize predictions\n","\n","Finally, it is a good practice to always inspect some of the model's prediction by looking at the data, this can give an idea if the model is getting some predictions wrong because the data is really hard, of if it is because the model is actually bad.\n","\n","\n","### Class map\n","```\n","0: Cassava Bacterial Blight (CBB)\n","1: Cassava Brown Streak Disease (CBSD)\n","2: Cassava Green Mottle (CGM)\n","3: Cassava Mosaic Disease (CMD)\n","4: Healthy\n","```\n","\n","\n","## Train set"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:41:38.486711Z","iopub.status.busy":"2021-01-20T23:41:38.478610Z","iopub.status.idle":"2021-01-20T23:42:07.973278Z","shell.execute_reply":"2021-01-20T23:42:07.973946Z"},"id":"ExEWWtxyCaO8","papermill":{"duration":29.642469,"end_time":"2021-01-20T23:42:07.974121","exception":false,"start_time":"2021-01-20T23:41:38.331652","status":"completed"},"tags":[]},"source":["train_dataset = get_dataset(TRAINING_FILENAMES, ordered=True)\n","x_samp, y_samp = dataset_to_numpy_util(train_dataset, 18)\n","y_samp = np.argmax(y_samp, axis=-1)\n","\n","x_samp_1, y_samp_1 = x_samp[:9,:,:,:], y_samp[:9]\n","samp_preds_1 = model.predict(x_samp_1, batch_size=9)\n","display_9_images_with_predictions(x_samp_1, samp_preds_1, y_samp_1)\n","\n","x_samp_2, y_samp_2 = x_samp[9:,:,:,:], y_samp[9:]\n","samp_preds_2 = model.predict(x_samp_2, batch_size=9)\n","display_9_images_with_predictions(x_samp_2, samp_preds_2, y_samp_2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-20T23:42:08.485006Z","iopub.status.busy":"2021-01-20T23:42:08.479584Z","iopub.status.idle":"2021-01-20T23:42:08.490084Z","shell.execute_reply":"2021-01-20T23:42:08.489432Z"},"id":"h9CeTJAYKYQd","papermill":{"duration":0.271568,"end_time":"2021-01-20T23:42:08.490212","exception":false,"start_time":"2021-01-20T23:42:08.218644","status":"completed"},"tags":[]},"source":["\n","save_data=True# You can immediately create a kaggle dataset from your models\n","if COLAB and save_data:\n","  \n","    import json\n","\n","\n","    \n","    data = {\"title\": \"Cassava Leaf Disease\", \n","        \"id\": \"aikhmelnytskyy/CassavaLeafDisease\", \n","        \"licenses\": [\n","                     {\n","                         \"name\": \"CC0-1.0\"\n","                      }\n","                     ]}\n","    \n","\n","    # for kaggle api Connection\n","    \n","    !kaggle datasets init -p /content/drive/MyDrive/Colab Notebooks/Cassava/\n","    \n","    with open(\"/content/drive/MyDrive/Colab Notebooks/Cassava/dataset-metadata.json\", \"w\", encoding=\"utf-8\") as file:\n","        json.dump(data, file)\n","    \n","    #if new dataset\n","    !kaggle datasets create -p /content/drive/MyDrive/Models/Cassava/\n","    #If you’d like to upload a new version of an existing dataset\n","    #!kaggle datasets version -p /content/drive/MyDrive/Models/Cassava/ -m \"Your message here\""],"execution_count":null,"outputs":[]}]}